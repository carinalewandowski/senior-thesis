{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling: Cleaning/Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import NLP libraries for preprocessing\n",
    "from nltk.corpus.reader.wordnet import NOUN\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Data\n",
    "1. Convert dataframe column with charge descriptions to list.\n",
    "2. Pad with space (' ') on front and back of each description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_charge_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aggravated Assault w/Firearm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Felony Battery w/Prior Convict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Possession of Cocaine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Possession of Cannabis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arrest case no charge</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    c_charge_desc\n",
       "0    Aggravated Assault w/Firearm\n",
       "1  Felony Battery w/Prior Convict\n",
       "2           Possession of Cocaine\n",
       "3          Possession of Cannabis\n",
       "4           arrest case no charge"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compas_path = 'compas-scores-two-years.csv'\n",
    "url = 'https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv'\n",
    "compas_df = pd.read_csv(url)\n",
    "# sample charge descriptions\n",
    "compas_df[['c_charge_desc']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' Aggravated Assault w/Firearm ',\n",
       " ' Felony Battery w/Prior Convict ',\n",
       " ' Possession of Cocaine ',\n",
       " ' Possession of Cannabis ',\n",
       " ' arrest case no charge ',\n",
       " ' Battery ',\n",
       " ' Possession Burglary Tools ',\n",
       " ' arrest case no charge ',\n",
       " ' Battery ',\n",
       " ' Insurance Fraud ']"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get non-NaN charge descriptions as a list\n",
    "compas_df_charge_filt = compas_df[compas_df['c_charge_desc'].isna() == False]\n",
    "charge_descs = list(compas_df_charge_filt['c_charge_desc'])\n",
    "charge_descs = [' ' + desc + ' ' for desc in charge_descs]\n",
    "print(len(charge_descs))\n",
    "charge_descs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Word Replacement Mappings\n",
    "\n",
    "Build dictionary with replacement word and all its mispellings as they appear in charge descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary with replacement (str) --> mispellings (list of str) mapping\n",
    "replacement_map = {\n",
    "    ' accident ': [' acc ', ' accd '],\n",
    "    ' aggravated ': [' agg ', ' aggr '],\n",
    "    ' alter ': [' alt '],\n",
    "    ' ammunition ': [' amm '],\n",
    "    ' amphetamine ': [' amp '],\n",
    "    ' attempt ': [' att ', ' attmp '],\n",
    "    ' attend ': [' attnd '],\n",
    "    ' battery ': [' batt ', ' bat '],\n",
    "    ' beverage ': [' bev '],\n",
    "    ' bodily ': [' bod '],\n",
    "    ' burglary ': ['burg ', ' burgl '],\n",
    "    ' business ': [' busn '],\n",
    "    ' cancel ': [' can '],\n",
    "    ' counterfeit ': [' cntrft ', ' conterfeit ', ' contrft ', ' countrfeit'],\n",
    "    ' commit ': [' com '],\n",
    "    ' communication ': [' communic '],\n",
    "    ' compensation ': [' compensatn '],\n",
    "    ' conspiracy ': [' consp '],\n",
    "    ' control ': [' cont ', ' contr '],\n",
    "    ' conveyance ': [' conv ', ' conve '],\n",
    "    ' control ': [' cont ', ' contr '],\n",
    "    ' convict ': [' convic '],\n",
    "    ' credit ': [' cred '],\n",
    "    ' criminal ': [' crim '],\n",
    "    ' cruelty ': [' crlty '],\n",
    "    ' custody ': [' cust '],\n",
    "    ' dangerous ': [' dang '],\n",
    "    ' degree ': [' deg '],\n",
    "    ' delinquency ': [' delinq '],\n",
    "    ' delivery ': [' deliv ', ' del '],\n",
    "    ' device ': [' dev '],\n",
    "    ' display ': [' disply '],\n",
    "    ' disqualified ': [' disqul '],\n",
    "    ' disorderly conduct ': [' doc '],\n",
    "    ' dollars ': [' dols '],\n",
    "    ' d u i ': [' dui '],\n",
    "    ' domestic ': [' dom ', ' dome '],\n",
    "    ' drive ': [' driv ', ' drivg '],\n",
    "    ' dwelling ': [' dwell '],\n",
    "    ' elderly ': [' elderlly '],\n",
    "    ' employee ': [' emplyee '],\n",
    "    ' enforcement ': [' enfor ', ' enforc '],\n",
    "    ' exhibition ': [' exhib '],\n",
    "    ' extinguisher ': [' extinquisher '],\n",
    "    ' facilitate ': [' fac '],\n",
    "    ' failure ': [' fail '],\n",
    "    ' family ': [' faml '],\n",
    "    ' felony ': [' fel '],\n",
    "    ' felon ': [' felo '],\n",
    "    ' firearm ': [' f arm '],\n",
    "    ' fraud ': [' frd ', ' fraudul'],\n",
    "    ' gambling ': [' gamb '],\n",
    "    ' gram ': [' g '], # check\n",
    "    ' great ': [' grt '],\n",
    "    ' informant ': ['informnt '],\n",
    "    ' injunction ': [' inj ', ' injunc ', ' injunct ', ' injunctn '],\n",
    "    ' instrument ': [' inst '],\n",
    "    ' intent ': [' int '],\n",
    "    ' interfere ': [' interf '],\n",
    "    ' introduce ': [' intoduce '],\n",
    "    ' lascivious ': [' lasc ', ' lasciv '],\n",
    "    ' lease ': [' leas '],\n",
    "    ' license ': [' lic ', ' licenc '],\n",
    "    ' license tag ': [' lictag '],\n",
    "    ' leave ': [' lve '],\n",
    "    ' manufacture ': [' man ', ' mfr '],\n",
    "    ' motor ': [' mot '],\n",
    "    ' occupied ': [' occup ', ' occp '], # not to confuse with unoccupied -- need space\n",
    "    ' offense ': [' offens ', ' offn '],\n",
    "    ' operate ': [' oper ', ' opert '],\n",
    "    ' permanent ': [' perm '],\n",
    "    ' person ': [' pers ', ' persn ', ' persnl '],\n",
    "    ' possession ': [' pos ', ' poss ', ' possess,'],\n",
    "    ' private ': [' priv '],\n",
    "    ' promise ': [' promis '],\n",
    "    ' property ': [' prop '],\n",
    "    ' public ': [' pub '],\n",
    "    ' purchase ': [' pur '],\n",
    "    ' railroad ': [' rail '],\n",
    "    ' redilver ': [' redeliv '],\n",
    "    ' revoke ': [' revk '],\n",
    "    ' scene ': [' scen '],\n",
    "    ' school ': [' ftsch ', ' scho ', ' scho '],\n",
    "    ' sell ': [' sel '],\n",
    "    ' sex ': [' sexual '], # for homogeneity\n",
    "    ' solicit ': [' solic ', ' solict '],\n",
    "    ' specialist ': [' speci '],\n",
    "    ' strangulation ': [' strang '],\n",
    "    ' structure ': [' struc ', ' struct '],\n",
    "    ' substance ': [' sub ', ' subst ', ' substa '],\n",
    "    ' sudden ': [' sudd '],\n",
    "    ' suspended ': [' susp ', ' suspd '],\n",
    "    ' traffick ': [' traf ', ' traff ', ' traffic '],\n",
    "    ' transmit ': [' trans '],\n",
    "    ' trespass ': [' tresspass '],\n",
    "    ' trirail ': [' tri rail '], # make 1-wd (tri-rail specific to FLA)\n",
    "    ' toward ': [' twrd '],\n",
    "    ' unauthorized ': [' unauth '],\n",
    "    ' uncovered ': [' uncov '],\n",
    "    ' unlawful ': [' unl ', ' unlaw '],\n",
    "    ' unoccupied ': [' unocc ', ' unoccup '],\n",
    "    ' vehicle ': [' veh '],\n",
    "    ' victim ': [' vict ', ' victm '],\n",
    "    ' vehicle identification number ': [' vin '],\n",
    "    ' violence ': [' viol ', ' vi '],\n",
    "    ' weapon ': [' weap ', ' wep '],\n",
    "}\n",
    "\n",
    "abbrev_map = {\n",
    "    'law enforcement officer ': ['leo '],\n",
    "    'driving under influence ': ['dui '],\n",
    "    'driving while intoxicated ': ['dwi '],\n",
    "    'driving while license suspended ': ['dwls '],\n",
    "    'firearm ': ['f arm '],\n",
    "    'vehicle identification number ': ['vin ']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary with replacement (str) --> mispellings (list of str) mapping\n",
    "r_replacement_map = {\n",
    "    ' accident ': [' acc ', ' accd '],\n",
    "    ' aggravated ': [' agg ', ' aggr '],\n",
    "    ' alcohol ': [' alch '], # NEW\n",
    "    ' alter ': [' alt '],\n",
    "    ' ammunition ': [' amm '],\n",
    "    ' amphetamine ': [' amp '],\n",
    "    ' attempt ': [' att ', ' attmp '],\n",
    "    ' attend ': [' attnd '],\n",
    "    ' battery ': [' batt ', ' bat '],\n",
    "    ' beverage ': [' bev '],\n",
    "    ' bodily ': [' bod '],\n",
    "    ' burglary ': ['burg ', ' burgl '],\n",
    "    ' business ': [' busn ', ' bus '], # ADDED bus\n",
    "    ' cancel ': [' can '],\n",
    "    ' church ': [' chur '], # NEW\n",
    "    ' counterfeit ': [' cntrft ', ' conterfeit ', ' contrft ', ' countrfeit'],\n",
    "    ' commit ': [' com '],\n",
    "    ' communication ': [' communic '],\n",
    "    ' compensation ': [' compensatn '],\n",
    "    ' conspiracy ': [' consp '],\n",
    "    ' control ': [' cont ', ' contr '],\n",
    "    ' conveyance ': [' conv ', ' conve '],\n",
    "    ' control ': [' cont ', ' contr '],\n",
    "    ' convict ': [' convic '],\n",
    "    ' credit ': [' cred '],\n",
    "    ' criminal ': [' crim ', ' crimin '], # ADDED crimin\n",
    "    ' cruelty ': [' crlty '],\n",
    "    ' custody ': [' cust '],\n",
    "    ' damage ': [' damg '],\n",
    "    ' dangerous ': [' dang '],\n",
    "    ' defendant ': [' deft '], # NEW\n",
    "    ' degree ': [' deg '],\n",
    "    ' delinquency ': [' delinq '],\n",
    "    ' delivery ': [' deliv ', ' del ', ' deliver '], # ADDED deliver\n",
    "    ' depend ': [' depnd '], # NEW\n",
    "    ' device ': [' dev '],\n",
    "    ' display ': [' disply '],\n",
    "    ' disqualified ': [' disqul '],\n",
    "    ' disorderly conduct ': [' doc '],\n",
    "    ' dollars ': [' dols '],\n",
    "    ' d u i ': [' dui '],\n",
    "    ' domestic ': [' dom ', ' dome '],\n",
    "    ' drive ': [' driv ', ' drivg ', ' drv '], # ADDED drv\n",
    "    ' dwelling ': [' dwell ', ' dwel '], # ADDED dwel\n",
    "    ' electronic ': [' elec '], # NEW\n",
    "    ' elderly ': [' elderlly '],\n",
    "    ' employee ': [' emplyee '],\n",
    "    ' enforcement ': [' enfor ', ' enforc '],\n",
    "    ' engage ': [' eng '], # NEW\n",
    "    ' establishment ': [' estab ', ' establishm '], # NEW\n",
    "    ' exhibition ': [' exhib '],\n",
    "    ' extinguisher ': [' extinquisher '],\n",
    "    ' facilitate ': [' fac '],\n",
    "    ' failure ': [' fail '],\n",
    "    ' family ': [' faml '],\n",
    "    ' felony ': [' fel '],\n",
    "    ' felon ': [' felo '],\n",
    "    ' firearm ': [' f arm '],\n",
    "    ' fraud ': [' frd ', ' fraudul', ' fraud ent '], # ADDED fraud ent\n",
    "    ' gambling ': [' gamb '],\n",
    "    ' gram ': [' g '], # check\n",
    "    ' great ': [' grt '],\n",
    "    ' hours ': [' hrs '], # NEW\n",
    "    ' informant ': ['informnt '],\n",
    "    ' injunction ': [' inj ', ' injunc ', ' injunct ', ' injunctn '],\n",
    "    ' instrument ': [' inst '],\n",
    "    ' insurance ': [' insur '], # NEW\n",
    "    ' intent ': [' int '],\n",
    "    ' interfere ': [' interf ', ' intrf '], # ADDED intrf\n",
    "    ' introduce ': [' intoduce '],\n",
    "    ' lascivious ': [' lasc ', ' lasciv '],\n",
    "    ' lease ': [' leas '],\n",
    "    ' license ': [' lic ', ' licenc '],\n",
    "    ' license tag ': [' lictag '],\n",
    "    ' leave ': [' lve '],\n",
    "    ' malicious ': [' malic '], # NEW\n",
    "    ' manufacture ': [' man ', ' mfr ', ' mfg '], # ADDED mfg\n",
    "    ' methadone ': [' methado '], # NEW\n",
    "    ' minor ': [' min '], # NEW\n",
    "    ' motor ': [' mot '],\n",
    "    ' obtain ': [' obt '], # NEW\n",
    "    ' occupied ': [' occup ', ' occp '],\n",
    "    ' offense ': [' offens ', ' offn '],\n",
    "    ' operate ': [' oper ', ' opert '],\n",
    "    ' paraphernalia ': [' para '], # NEW\n",
    "    ' pedestrian ': [' ped '], # NEW\n",
    "    ' permanent ': [' perm '],\n",
    "    ' person ': [' pers ', ' persn ', ' persnl ', ' prson '], # ADDED prson\n",
    "    ' possession ': [' pos ', ' poss ', ' possess ', ' posses '],\n",
    "    ' private ': [' priv '],\n",
    "    ' promise ': [' promis '],\n",
    "    ' property ': [' prop '],\n",
    "    ' prostitute ': [' prostitut '], # NEW\n",
    "    ' prostitution violation ': [' prostitutionviolation '], # NEW\n",
    "    ' protect ': [' prot '], # NEW\n",
    "    ' public ': [' pub '],\n",
    "    ' purchase ': [' pur '],\n",
    "    ' railroad ': [' rail '],\n",
    "    ' receipt ': [' rcpt '],\n",
    "    ' redilver ': [' redeliv '],\n",
    "    ' registration ': [' reg '], # NEW\n",
    "    ' responsibility ': [' resp '], # NEW\n",
    "    ' revoke ': [' revk '],\n",
    "    ' scene ': [' scen '],\n",
    "    ' school ': [' ftsch ', ' scho ', ' scho ', ' sch '], # ADDED sch\n",
    "    ' sell ': [' sel '],\n",
    "    ' sex ': [' sexual '], # for homogeneity\n",
    "    ' shop ': [' shp '], # NEW\n",
    "    ' solicit ': [' solic ', ' solict ', ' sol '], # ADDED sol\n",
    "    ' specialist ': [' speci '],\n",
    "    ' strangulation ': [' strang '],\n",
    "    ' structure ': [' struc ', ' struct '],\n",
    "    ' substance ': [' sub ', ' subst ', ' substa '],\n",
    "    ' sudden ': [' sudd '],\n",
    "    ' suspended ': [' susp ', ' suspd '],\n",
    "    ' traffick ': [' traf ', ' traff ', ' traffic '],\n",
    "    ' obstruct traffic ': [' obstruct traffick '], # NEW (acct for traffic/traffick diff)\n",
    "    ' transmit ': [' trans '],\n",
    "    ' trespass ': [' tresspass '],\n",
    "    ' trirail ': [' tri rail '], # make 1-wd (tri-rail specific to FLA)\n",
    "    ' toward ': [' twrd '],\n",
    "    ' unauthorized ': [' unauth ', ' unauthorizd '], # ADDED unauthorizd\n",
    "    ' uncovered ': [' uncov '],\n",
    "    ' under ': [' und '], # NEW\n",
    "    ' unlawful ': [' unl ', ' unlaw '],\n",
    "    ' unoccupied ': [' unocc ', ' unoccup '],\n",
    "    ' vehicle ': [' veh '],\n",
    "    ' verification ': [' verif '], # NEW\n",
    "    ' victim ': [' vict ', ' victm '],\n",
    "    ' vehicle identification number ': [' vin '],\n",
    "    ' violence ': [' viol ', ' vi '],\n",
    "    ' weapon ': [' weap ', ' wep '],\n",
    "    ' witness ': [' wit '], # NEW\n",
    "    ' years ': [' yrs '] # NEW\n",
    "}\n",
    "\n",
    "abbrev_map = {\n",
    "    'law enforcement officer ': ['leo '],\n",
    "    'driving under influence ': ['dui '],\n",
    "    'driving while intoxicated ': ['dwi '],\n",
    "    'driving while license suspended ': ['dwls '],\n",
    "    'firearm ': ['f arm '],\n",
    "    'vehicle identification number ': ['vin ']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Pre-processing Functions\n",
    "1. **get_chars_to_rmv:** Get list of non-alpha characters and replace with space\n",
    "2. **check_desc:** Get charge description containing a certain token (for reference).\n",
    "3. **clean_descs:** Remove chars_to_rmv; replace mispellings and remove any excess whitespace.\n",
    "4. **tokenize_descs:** Tokenize descriptions.\n",
    "5. **stem_tokens:** Stem each token in each description (exclude English stop words and tokens < 3 chars in length)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a list of non-alpha chars to remove, which can be fed into a replacement function as a regex\n",
    "def get_chars_to_rmv(charge_descs):\n",
    "    chars=[]\n",
    "    for d in charge_descs:\n",
    "        for t in d:\n",
    "            for c in t:\n",
    "                if not c.isalpha() and c not in chars:\n",
    "                    chars.append(c)\n",
    "    chars_to_rmv = ''.join(sorted(chars)).strip()\n",
    "    chars_to_rmv = '[' + chars_to_rmv + ']'\n",
    "    return chars_to_rmv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE WHEN DONE -- simply for checking full description of confusing tokens for context\n",
    "def check_desc(keyword):\n",
    "    for d in charge_descs:\n",
    "        if keyword in d.lower():\n",
    "            print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_descs(chars_to_rmv, charge_descs, replacement_map):\n",
    "    # remove non-alpha characters\n",
    "    charge_descs_clean = [re.sub(chars_to_rmv, ' ', desc.lower()) for desc in charge_descs]\n",
    "    # replace mispellings using replacement_map\n",
    "    for repl, mispellings in replacement_map.items():\n",
    "        for misp in mispellings:\n",
    "            charge_descs_clean = [re.sub(misp, repl, desc) for desc in charge_descs_clean]\n",
    "\n",
    "    # remove extra spaces\n",
    "    charge_descs_clean = [re.sub(' +', ' ', desc) for desc in charge_descs_clean]\n",
    "    return charge_descs_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_descs(charge_descs_clean):\n",
    "    # use nltk tokenizer to tokenize each description\n",
    "    tokenized_descs = [word_tokenize(desc.lower()) for desc in charge_descs_clean]\n",
    "    # sample of tokenized descriptions\n",
    "    return tokenized_descs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_tokens(tokenized_descs):\n",
    "    # make stemmer\n",
    "    stemmer = SnowballStemmer(language='english')\n",
    "\n",
    "    # get english stop words\n",
    "    swds = stopwords.words('english')\n",
    "\n",
    "    # list for toring tokenized & stemmed descriptions\n",
    "    tokenized_stemmed = []\n",
    "    # list for storing stemmed/token/description triplets\n",
    "    stem_token_descs = []\n",
    "\n",
    "    # stem each token in each description\n",
    "    for desc in tokenized_descs:\n",
    "        stemmed = [(stemmer.stem(token)) for token in desc if (len(token) > 2 and token not in swds)]\n",
    "        tokenized_stemmed.append(stemmed)\n",
    "        # also build a list containing stemmed token, original token, and the description it came from \n",
    "        # (for reference and debugging purposes)\n",
    "        triplet = [(stemmer.stem(token), token, ' '.join(desc)) for token in desc if len(token) > 2]\n",
    "        stem_token_descs.append(triplet)\n",
    "    return tokenized_stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preprocess First Charge Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[#$()+,-./0123456789<>]'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars_to_rmv = get_chars_to_rmv(charge_descs)\n",
    "chars_to_rmv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' aggravated assault w firearm ',\n",
       " ' felony battery w prior convict ',\n",
       " ' possession of cocaine ',\n",
       " ' possession of cannabis ',\n",
       " ' arrest case no charge ',\n",
       " ' battery ',\n",
       " ' possession burglary tools ',\n",
       " ' arrest case no charge ',\n",
       " ' battery ',\n",
       " ' insurance fraud ']"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean descriptions\n",
    "charge_descs_clean = clean_descs(chars_to_rmv, charge_descs, r_replacement_map)\n",
    "# sample of cleaned charge descriptions\n",
    "charge_descs_clean[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['aggravated', 'assault', 'w', 'firearm'],\n",
       " ['felony', 'battery', 'w', 'prior', 'convict'],\n",
       " ['possession', 'of', 'cocaine'],\n",
       " ['possession', 'of', 'cannabis'],\n",
       " ['arrest', 'case', 'no', 'charge'],\n",
       " ['battery'],\n",
       " ['possession', 'burglary', 'tools'],\n",
       " ['arrest', 'case', 'no', 'charge'],\n",
       " ['battery'],\n",
       " ['insurance', 'fraud']]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize\n",
    "tokenized_descs = tokenize_descs(charge_descs_clean)\n",
    "# sample of tokenized descriptions\n",
    "tokenized_descs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aggrav, assault, firearm',\n",
      " 'feloni, batteri, prior, convict',\n",
      " 'possess, cocain',\n",
      " 'possess, cannabi',\n",
      " 'arrest, case, charg',\n",
      " 'batteri',\n",
      " 'possess, burglari, tool',\n",
      " 'arrest, case, charg',\n",
      " 'batteri',\n",
      " 'insur, fraud']\n",
      "\n",
      "number of unique tokens (vocab length): 421\n",
      "number of unique charge descriptions: 406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['abet',\n",
       " 'abus',\n",
       " 'accessori',\n",
       " 'accid',\n",
       " 'act',\n",
       " 'actual',\n",
       " 'adult',\n",
       " 'aggrav',\n",
       " 'aggress',\n",
       " 'agre']"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stem and remove stopwords\n",
    "tokenized_stemmed = stem_tokens(tokenized_descs)\n",
    "tokenized_stemmed = [', '.join(desc) for desc in tokenized_stemmed]\n",
    "# sample of stemmed, tokenized descriptions\n",
    "pprint(tokenized_stemmed[:10])\n",
    "\n",
    "# make sorted list of unique tokens (vocabulary)\n",
    "flat_unq_tokens = sorted(set([token for desc in tokenized_stemmed for token in desc.split(', ')]))\n",
    "print('\\nnumber of unique tokens (vocab length):', len(flat_unq_tokens))\n",
    "print('number of unique charge descriptions:', len(set([' '.join(desc) for desc in tokenized_stemmed])))\n",
    "\n",
    "# sample of stemmed, tokenized descriptions\n",
    "flat_unq_tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'id': compas_df_charge_filt['id'], 'name': compas_df_charge_filt['name'], 'charge description': compas_df_charge_filt['c_charge_desc'], \n",
    "     'tokenized_stemmed description': tokenized_stemmed}\n",
    "charge_mappings = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>charge description</th>\n",
       "      <th>tokenized_stemmed description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>miguel hernandez</td>\n",
       "      <td>Aggravated Assault w/Firearm</td>\n",
       "      <td>aggrav, assault, firearm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>Felony Battery w/Prior Convict</td>\n",
       "      <td>feloni, batteri, prior, convict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ed philo</td>\n",
       "      <td>Possession of Cocaine</td>\n",
       "      <td>possess, cocain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>marcu brown</td>\n",
       "      <td>Possession of Cannabis</td>\n",
       "      <td>possess, cannabi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>bouthy pierrelouis</td>\n",
       "      <td>arrest case no charge</td>\n",
       "      <td>arrest, case, charg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                name              charge description  \\\n",
       "0   1    miguel hernandez    Aggravated Assault w/Firearm   \n",
       "1   3         kevon dixon  Felony Battery w/Prior Convict   \n",
       "2   4            ed philo           Possession of Cocaine   \n",
       "3   5         marcu brown          Possession of Cannabis   \n",
       "4   6  bouthy pierrelouis           arrest case no charge   \n",
       "\n",
       "     tokenized_stemmed description  \n",
       "0         aggrav, assault, firearm  \n",
       "1  feloni, batteri, prior, convict  \n",
       "2                  possess, cocain  \n",
       "3                 possess, cannabi  \n",
       "4              arrest, case, charg  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charge_mappings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Second Charge Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' Felony Battery (Dom Strang) ',\n",
       " ' Driving Under The Influence ',\n",
       " ' Poss of Firearm by Convic Felo ',\n",
       " ' Battery ',\n",
       " ' Driving License Suspended ',\n",
       " ' Grand Theft (Motor Vehicle) ',\n",
       " ' Criminal Mischief>$200<$1000 ',\n",
       " ' Grand Theft in the 3rd Degree ',\n",
       " ' Possession of Cocaine ',\n",
       " ' Poss Cocaine/Intent To Del/Sel ']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get non-NaN r_charge descriptions as a list\n",
    "r_compas_df_charge_filt = compas_df[compas_df['r_charge_desc'].isna() == False]\n",
    "r_charge_descs = list(r_compas_df_charge_filt['r_charge_desc'])\n",
    "r_charge_descs = [' ' + desc + ' ' for desc in r_charge_descs]\n",
    "print(len(r_charge_descs))\n",
    "r_charge_descs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"$()+,-./0123456789<>]'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get chars to remove from r crimes\n",
    "r_chars_to_rmv = get_chars_to_rmv(r_charge_descs)\n",
    "r_chars_to_rmv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' felony battery domestic strangulation ',\n",
       " ' driving under the influence ',\n",
       " ' possession of firearm by convict felon ',\n",
       " ' battery ',\n",
       " ' driving license suspended ',\n",
       " ' grand theft motor vehicle ',\n",
       " ' criminal mischief ',\n",
       " ' grand theft in the rd degree ',\n",
       " ' possession of cocaine ',\n",
       " ' possession cocaine intent to delivery sell ',\n",
       " ' prowling loitering ',\n",
       " ' operating w o valid license ',\n",
       " ' possession cannabis grams or less ',\n",
       " ' driving license suspended ',\n",
       " ' possession cannabis grams or less ',\n",
       " ' false imprisonment ',\n",
       " ' grand theft motor vehicle ',\n",
       " ' resist obstruct w o violence ',\n",
       " ' possession cannabis grams or less ',\n",
       " ' grand theft in the rd degree ']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample of cleaned charge descriptions\n",
    "r_charge_descs_clean = clean_descs(r_chars_to_rmv, r_charge_descs, r_replacement_map)\n",
    "# sample of cleaned charge descriptions\n",
    "r_charge_descs_clean[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['felony', 'battery', 'domestic', 'strangulation'],\n",
       " ['driving', 'under', 'the', 'influence'],\n",
       " ['possession', 'of', 'firearm', 'by', 'convict', 'felon'],\n",
       " ['battery'],\n",
       " ['driving', 'license', 'suspended'],\n",
       " ['grand', 'theft', 'motor', 'vehicle'],\n",
       " ['criminal', 'mischief'],\n",
       " ['grand', 'theft', 'in', 'the', 'rd', 'degree'],\n",
       " ['possession', 'of', 'cocaine'],\n",
       " ['possession', 'cocaine', 'intent', 'to', 'delivery', 'sell']]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize each description\n",
    "r_tokenized_descs = tokenize_descs(r_charge_descs_clean)\n",
    "# sample of tokenized descriptions\n",
    "r_tokenized_descs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feloni, batteri, domest, strangul', 'drive, influenc', 'possess, firearm, convict, felon', 'batteri', 'drive, licens, suspend', 'grand, theft, motor, vehicl', 'crimin, mischief', 'grand, theft, degre', 'possess, cocain', 'possess, cocain, intent, deliveri, sell']\n"
     ]
    }
   ],
   "source": [
    "# stem each token in each description & remove stop words\n",
    "r_tokenized_stemmed = stem_tokens(r_tokenized_descs)\n",
    "r_tokenized_stemmed = [', '.join(desc) for desc in r_tokenized_stemmed]\n",
    "# sample of stemmed, tokenized descriptions\n",
    "print(r_tokenized_stemmed[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>charge description</th>\n",
       "      <th>r_tokenized_stemmed description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>Felony Battery (Dom Strang)</td>\n",
       "      <td>feloni, batteri, domest, strangul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ed philo</td>\n",
       "      <td>Driving Under The Influence</td>\n",
       "      <td>drive, influenc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>edward riddle</td>\n",
       "      <td>Poss of Firearm by Convic Felo</td>\n",
       "      <td>possess, firearm, convict, felon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13</td>\n",
       "      <td>bo bradac</td>\n",
       "      <td>Battery</td>\n",
       "      <td>batteri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15</td>\n",
       "      <td>ellyaher lanza</td>\n",
       "      <td>Driving License Suspended</td>\n",
       "      <td>drive, licens, suspend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7201</th>\n",
       "      <td>10985</td>\n",
       "      <td>kyle miller</td>\n",
       "      <td>Operating W/O Valid License</td>\n",
       "      <td>oper, valid, licens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7205</th>\n",
       "      <td>10990</td>\n",
       "      <td>christopher tun</td>\n",
       "      <td>Assault</td>\n",
       "      <td>assault</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7206</th>\n",
       "      <td>10992</td>\n",
       "      <td>alexander vega</td>\n",
       "      <td>Possess Cannabis/20 Grams Or Less</td>\n",
       "      <td>possess, cannabi, gram, less</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7207</th>\n",
       "      <td>10994</td>\n",
       "      <td>jarred payne</td>\n",
       "      <td>Possession of Cannabis</td>\n",
       "      <td>possess, cannabi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7213</th>\n",
       "      <td>11001</td>\n",
       "      <td>florencia sanmartin</td>\n",
       "      <td>Operating W/O Valid License</td>\n",
       "      <td>oper, valid, licens</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3413 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                 name                 charge description  \\\n",
       "1         3          kevon dixon        Felony Battery (Dom Strang)   \n",
       "2         4             ed philo        Driving Under The Influence   \n",
       "6         8        edward riddle     Poss of Firearm by Convic Felo   \n",
       "9        13            bo bradac                            Battery   \n",
       "11       15       ellyaher lanza          Driving License Suspended   \n",
       "...     ...                  ...                                ...   \n",
       "7201  10985          kyle miller        Operating W/O Valid License   \n",
       "7205  10990      christopher tun                            Assault   \n",
       "7206  10992       alexander vega  Possess Cannabis/20 Grams Or Less   \n",
       "7207  10994         jarred payne             Possession of Cannabis   \n",
       "7213  11001  florencia sanmartin        Operating W/O Valid License   \n",
       "\n",
       "        r_tokenized_stemmed description  \n",
       "1     feloni, batteri, domest, strangul  \n",
       "2                       drive, influenc  \n",
       "6      possess, firearm, convict, felon  \n",
       "9                               batteri  \n",
       "11               drive, licens, suspend  \n",
       "...                                 ...  \n",
       "7201                oper, valid, licens  \n",
       "7205                            assault  \n",
       "7206       possess, cannabi, gram, less  \n",
       "7207                   possess, cannabi  \n",
       "7213                oper, valid, licens  \n",
       "\n",
       "[3413 rows x 4 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'id': r_compas_df_charge_filt['id'], 'name': r_compas_df_charge_filt['name'], \n",
    "     'charge description': r_compas_df_charge_filt['r_charge_desc'], \n",
    "     'r_tokenized_stemmed description': r_tokenized_stemmed}\n",
    "r_charge_mappings = pd.DataFrame(data=d)\n",
    "r_charge_mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for Common Token Analysis / Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# rows total: 7214\n",
      "# rows where c_charge is non-NaN: 7185\n",
      "# rows where r_charge is non-NaN: 3413\n",
      "# rows where c_charge and r_charge both non-NaN: 3393\n"
     ]
    }
   ],
   "source": [
    "# check lengths of df slices before merge\n",
    "print('# rows total:', len(compas_df))\n",
    "print('# rows where c_charge is non-NaN:', len(charge_mappings))\n",
    "print('# rows where r_charge is non-NaN:', len(r_charge_mappings))\n",
    "# get df rows where c_charge and r_charge both non-NaN\n",
    "cr_idx = (compas_df['c_charge_desc'].isna() == False) & (compas_df['r_charge_desc'].isna() == False)\n",
    "print('# rows where c_charge and r_charge both non-NaN:', len(cr_idx[cr_idx == True]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df_merged = compas_df.merge(charge_mappings[['id', 'tokenized_stemmed description']], how='outer', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_df_merged = c_df_merged.merge(r_charge_mappings[['id', 'r_tokenized_stemmed description']], how='outer', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>race</th>\n",
       "      <th>c_charge_desc</th>\n",
       "      <th>tokenized_stemmed description</th>\n",
       "      <th>two_year_recid</th>\n",
       "      <th>r_charge_desc</th>\n",
       "      <th>r_tokenized_stemmed description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>miguel hernandez</td>\n",
       "      <td>Other</td>\n",
       "      <td>Aggravated Assault w/Firearm</td>\n",
       "      <td>aggrav, assault, firearm</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>African-American</td>\n",
       "      <td>Felony Battery w/Prior Convict</td>\n",
       "      <td>feloni, batteri, prior, convict</td>\n",
       "      <td>1</td>\n",
       "      <td>Felony Battery (Dom Strang)</td>\n",
       "      <td>feloni, batteri, domest, strangul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ed philo</td>\n",
       "      <td>African-American</td>\n",
       "      <td>Possession of Cocaine</td>\n",
       "      <td>possess, cocain</td>\n",
       "      <td>1</td>\n",
       "      <td>Driving Under The Influence</td>\n",
       "      <td>drive, influenc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>marcu brown</td>\n",
       "      <td>African-American</td>\n",
       "      <td>Possession of Cannabis</td>\n",
       "      <td>possess, cannabi</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>bouthy pierrelouis</td>\n",
       "      <td>Other</td>\n",
       "      <td>arrest case no charge</td>\n",
       "      <td>arrest, case, charg</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                name              race                   c_charge_desc  \\\n",
       "0   1    miguel hernandez             Other    Aggravated Assault w/Firearm   \n",
       "1   3         kevon dixon  African-American  Felony Battery w/Prior Convict   \n",
       "2   4            ed philo  African-American           Possession of Cocaine   \n",
       "3   5         marcu brown  African-American          Possession of Cannabis   \n",
       "4   6  bouthy pierrelouis             Other           arrest case no charge   \n",
       "\n",
       "     tokenized_stemmed description  two_year_recid  \\\n",
       "0         aggrav, assault, firearm               0   \n",
       "1  feloni, batteri, prior, convict               1   \n",
       "2                  possess, cocain               1   \n",
       "3                 possess, cannabi               0   \n",
       "4              arrest, case, charg               0   \n",
       "\n",
       "                 r_charge_desc    r_tokenized_stemmed description  \n",
       "0                          NaN                                NaN  \n",
       "1  Felony Battery (Dom Strang)  feloni, batteri, domest, strangul  \n",
       "2  Driving Under The Influence                    drive, influenc  \n",
       "3                          NaN                                NaN  \n",
       "4                          NaN                                NaN  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_filt = cr_df_merged[['id', 'name', 'race', 'c_charge_desc', 'tokenized_stemmed description', 'two_year_recid', 'r_charge_desc', 'r_tokenized_stemmed description']]\n",
    "merged_filt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_filt.to_csv('merged_filt_NEW.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Model Building: Implemented based on Gensim Documentation examples\n",
    "https://radimrehurek.com/gensim/auto_examples/tutorials/run_lda.html#sphx-glr-auto-examples-tutorials-run-lda-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import topic modeling libraries\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, corpus, dictionary):\n",
    "    return pyLDAvis.gensim.prepare(model, corpus, dictionary, sort_topics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary representation of documents (charge descriptions)\n",
    "tokenized_stemmed = stem_tokens(tokenized_descs)\n",
    "dictionary = Dictionary(tokenized_stemmed)\n",
    "\n",
    "# dictionary.filter_extremes(no_below=3, no_above=0.5)\n",
    "\n",
    "# create a BoW representation of the documents\n",
    "corpus = [dictionary.doc2bow(desc) for desc in tokenized_stemmed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 428\n",
      "Number of documents: 7185\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up log to terminal: https://miningthedetails.com/blog/python/lda/GensimLDA/\n",
    "#import logging\n",
    "#logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "#Supress default INFO logging\n",
    "\n",
    "#import logging\n",
    "#logger = logging.getLogger()\n",
    "#logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: set random seed\n",
    "# set training parameters \n",
    "num_topics = 5\n",
    "chunksize = 10000\n",
    "passes = 20\n",
    "iterations = 400\n",
    "eval_every = 1\n",
    "\n",
    "temp = dictionary[0]\n",
    "id2word = dictionary.id2token\n",
    "\n",
    "# build model\n",
    "model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average topic coherence: -19.5958.\n"
     ]
    }
   ],
   "source": [
    "top_topics = model.top_topics(corpus)\n",
    "avg_topic_coher = sum(t[1] for t in top_topics) / num_topics\n",
    "\n",
    "print('Average topic coherence: %.4f.' % avg_topic_coher)\n",
    "\n",
    "#pprint(top_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.2.2/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el138349971444648379584889\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el138349971444648379584889_data = {\"mdsDat\": {\"x\": [-0.24799953969980887, 0.27819395614022263, 0.2797092396129294, -0.15591067927859742, -0.1539929767747462], \"y\": [-0.12339878704628633, 0.0026626850088044204, -0.02769485563227499, 0.3857497369257661, -0.2373187792560096], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [18.16528885421662, 18.704817550119323, 19.721857661298092, 22.629155109391885, 20.778880824974078]}, \"tinfo\": {\"Term\": [\"batteri\", \"arrest\", \"charg\", \"case\", \"possess\", \"grand\", \"theft\", \"cocain\", \"licens\", \"degre\", \"drive\", \"burglari\", \"suspend\", \"revok\", \"unoccupi\", \"aggrav\", \"violenc\", \"cannabi\", \"dead\", \"assault\", \"weapon\", \"feloni\", \"deliveri\", \"influenc\", \"dwell\", \"intent\", \"sell\", \"convey\", \"petit\", \"damag\", \"grand\", \"degre\", \"deliveri\", \"intent\", \"sell\", \"motor\", \"injunct\", \"forg\", \"utter\", \"instrument\", \"obstruct\", \"conduct\", \"heroin\", \"repeat\", \"prot\", \"stalk\", \"loiter\", \"prowl\", \"molest\", \"releas\", \"pretrial\", \"bill\", \"defraud\", \"jail\", \"contraband\", \"introduc\", \"near\", \"theft\", \"pay\", \"consider\", \"violenc\", \"sale\", \"disord\", \"vehicl\", \"cannabi\", \"domest\", \"resist\", \"lascivi\", \"possess\", \"lewd\", \"batteri\", \"influenc\", \"strangul\", \"tamper\", \"deliv\", \"harm\", \"bodili\", \"child\", \"pregnant\", \"physic\", \"evid\", \"convict\", \"prior\", \"great\", \"victim\", \"wit\", \"abus\", \"neglect\", \"imprison\", \"enhanc\", \"solicit\", \"methylenediox\", \"commit\", \"cruelti\", \"toward\", \"reckless\", \"return\", \"elder\", \"yrs\", \"famili\", \"aggrav\", \"domest\", \"feloni\", \"drive\", \"firearm\", \"fals\", \"person\", \"assault\", \"licens\", \"suspend\", \"revok\", \"unoccupi\", \"burglari\", \"dead\", \"dwell\", \"convey\", \"offens\", \"driver\", \"structur\", \"info\", \"occupi\", \"trespass\", \"arm\", \"pawn\", \"ownership\", \"fraud\", \"dwel\", \"act\", \"assign\", \"unattend\", \"ent\", \"item\", \"display\", \"throw\", \"use\", \"poss\", \"construct\", \"site\", \"assault\", \"weapon\", \"prostitut\", \"drive\", \"oper\", \"aggrav\", \"person\", \"feloni\", \"crimin\", \"fals\", \"attempt\", \"case\", \"arrest\", \"charg\", \"offic\", \"level\", \"law\", \"enforc\", \"minor\", \"carri\", \"conceal\", \"valid\", \"intox\", \"culpabl\", \"neglig\", \"stolen\", \"deal\", \"expos\", \"ecstasi\", \"name\", \"ident\", \"regist\", \"expir\", \"month\", \"protect\", \"delinqu\", \"obey\", \"polic\", \"offer\", \"tetrahydrocannabinol\", \"secur\", \"failur\", \"firearm\", \"resist\", \"vehicl\", \"violenc\", \"disord\", \"oper\", \"fals\", \"unlaw\", \"use\", \"cocain\", \"petit\", \"damag\", \"gram\", \"less\", \"injuri\", \"methylenedioxymethcath\", \"robberi\", \"mischief\", \"alprazolam\", \"leav\", \"accid\", \"pyrrolidinovalerophenon\", \"control\", \"substanc\", \"flee\", \"elud\", \"properti\", \"tool\", \"oxycodon\", \"leo\", \"methamphetamin\", \"scene\", \"prescript\", \"public\", \"servant\", \"attend\", \"snatch\", \"sudden\", \"hydromorphon\", \"possess\", \"cannabi\", \"crimin\", \"attempt\", \"feloni\", \"theft\", \"weapon\", \"vehicl\"], \"Freq\": [1593.0, 1105.0, 1105.0, 1104.0, 1202.0, 539.0, 666.0, 530.0, 496.0, 439.0, 519.0, 332.0, 243.0, 215.0, 215.0, 354.0, 278.0, 309.0, 173.0, 224.0, 235.0, 363.0, 138.0, 139.0, 143.0, 131.0, 129.0, 121.0, 121.0, 121.0, 538.5075539958068, 438.9286591212316, 137.23521688491567, 130.33693862483062, 128.34829811970542, 101.72201513058482, 85.95922608453553, 66.2315051679028, 64.27343059853258, 56.38235675251406, 48.513235465839315, 33.717098263221786, 27.7993027509897, 21.88567862105024, 20.899626879827974, 16.95207191862888, 13.999041818933952, 13.999026968284968, 11.042770152580058, 11.86854296448939, 11.868381257422666, 8.955390157462933, 7.097522817225997, 7.097644922562094, 7.097639972345767, 7.097636672201547, 6.111613394723167, 589.607251092016, 5.126033161606168, 5.125253915052492, 219.3758988961275, 6.779754818019133, 33.716949756731935, 105.6544405806126, 106.31039704641651, 67.88506222962285, 44.56821666547241, 11.688481320656557, 105.50779537210379, 11.105203105948316, 1592.8216469873216, 138.45705315336056, 97.5324232973964, 78.07237927997616, 72.23759228981557, 73.19989061999483, 69.305155131269, 65.3916481952905, 51.78822096114295, 50.81132752489014, 50.81131393224187, 47.9034284946223, 44.98371065668884, 44.001770949767995, 31.347627085086856, 26.480743693433418, 26.48071650813689, 26.47195944449276, 24.530878299951983, 20.640227402029517, 17.702482314335832, 14.797488712634436, 13.776338463174318, 12.848738765851172, 11.87587554980866, 8.954384720817261, 5.05707002708333, 4.086474234679368, 3.1142723859289556, 3.1112775432231476, 205.51969997034675, 103.67943341818278, 195.77880044486332, 147.24505366493938, 32.93767808820792, 24.591781859580202, 24.625780471050717, 36.64996285744714, 495.0717335778672, 242.31367335939507, 214.6601254784159, 214.6346580056559, 330.6496019029023, 173.11144133558233, 142.48975051086938, 120.72484986825577, 70.3602066237355, 65.40450442786937, 62.46048177488127, 51.59467775048541, 36.76301351524244, 23.916389731716723, 20.925638494072466, 18.97704361535953, 18.9770382409632, 16.009454234448118, 15.021877557483776, 13.020821404692063, 11.067713824524256, 10.03944221852107, 7.115063431999038, 18.977373245001335, 5.139211406546974, 5.135484262689547, 50.5069250130589, 4.150794532289131, 4.1507510892521005, 4.150746610588489, 187.51760386429288, 184.67916301874595, 19.929565792237256, 371.76410648058993, 37.49331515251395, 148.28183059591086, 36.671885251008064, 100.9731694288025, 31.82530838123247, 24.469664128152193, 20.950045419289285, 1103.9280395049002, 1104.8982611368604, 1104.8970771375807, 120.5867499709335, 63.24446441230928, 58.44575233174308, 57.47668181019375, 58.42741267623387, 42.905190341844204, 39.028090145033495, 40.84293904091824, 16.69577837042327, 13.785137113417386, 13.785129918977319, 13.78419669732285, 13.784190530659934, 11.84326935036376, 9.89676631235236, 8.93086134443273, 7.960568281960501, 7.95865250534824, 6.989507469955354, 6.989506442178201, 7.816055105990338, 6.008425316824755, 5.045352902737415, 5.045151458415525, 5.043908361949576, 4.069060961970331, 3.10323153567141, 20.43562406740335, 56.660791195453044, 57.47985969714928, 67.99758429839056, 58.15906417282469, 15.72984873585198, 14.042337318053393, 11.244438075791013, 8.61551567517118, 8.048420103513331, 529.7667285147633, 121.13380899313154, 121.12354109225625, 107.49070565151987, 95.79176894122726, 76.25588708757877, 72.36191402938636, 58.71890128690006, 56.765723817570226, 52.87051634629464, 49.82187087744174, 49.82181425298838, 38.239942937564734, 38.23238546052344, 36.28163906772437, 35.311224285957074, 34.33569065360636, 115.10791771614456, 30.433322076462975, 30.432159387687392, 27.496585402260052, 26.530196619126393, 26.496841041135934, 22.631686054738356, 23.573918846070185, 16.76862783078652, 15.80250423884275, 13.851929606885527, 13.851919225735745, 13.848398128477868, 1096.781052647057, 202.41431602381434, 60.66969297926182, 28.36514789229346, 66.66177190766793, 76.50195431208422, 50.23339475465451, 41.008905131436286], \"Total\": [1593.0, 1105.0, 1105.0, 1104.0, 1202.0, 539.0, 666.0, 530.0, 496.0, 439.0, 519.0, 332.0, 243.0, 215.0, 215.0, 354.0, 278.0, 309.0, 173.0, 224.0, 235.0, 363.0, 138.0, 139.0, 143.0, 131.0, 129.0, 121.0, 121.0, 121.0, 539.3710805055397, 439.77605752085793, 138.04116842961022, 131.13863155688148, 129.16625261129687, 102.5427999964972, 86.7657814500948, 67.04456689189831, 65.072609640488, 57.18403959790175, 49.29562180125188, 34.504515800979114, 28.587568318827145, 22.67187827147074, 21.68581381013312, 17.740899456641337, 14.783279789807954, 14.78327921598152, 11.825068423406643, 12.808703652944073, 12.808701595829739, 9.851455077656652, 7.8806914905922305, 7.8808440859626, 7.880843783657863, 7.880844524537157, 6.894825505928473, 666.7342453282927, 5.9086889772482305, 5.908556521096655, 278.14500494924283, 7.875434730408141, 50.03880558770013, 215.4283982993561, 309.40340407077804, 172.22323896341646, 102.63593637589999, 17.674729659701786, 1202.9788813190262, 34.476644992113215, 1593.940047837266, 139.24191894605562, 98.34744743809293, 78.87356609303433, 73.03056047565873, 74.00516990450471, 70.11042769603073, 66.2157639492563, 52.58396072306342, 51.610342307434955, 51.610330797646675, 48.68904213768287, 45.76803500701338, 44.79443003486731, 32.13641712779892, 27.26796044847347, 27.26795929959405, 27.26813157265147, 25.32056658923277, 21.42565300896792, 18.504216586957806, 15.583613937788032, 14.610146864951451, 13.636253134274243, 12.662625018379051, 9.741575055399922, 5.846257273826342, 4.873052505034645, 3.8994609123390807, 3.8990313821511395, 354.68753358751843, 172.22323896341646, 363.8424293033621, 519.6473789030318, 96.3147010680504, 60.70249677050166, 61.889730908387264, 224.79646657748947, 496.1705037145845, 243.13980590208217, 215.4644820100617, 215.46449135576444, 332.0897835959077, 173.95041852436015, 143.3100032450631, 121.56467968221475, 71.15568212098468, 66.21340165889804, 63.248574051232424, 52.37606305306699, 37.549712409774266, 24.700345273697014, 21.734567429793277, 19.758327020273317, 19.75832685148034, 16.79299795333763, 15.804636448498774, 13.827146435262247, 11.850934563400353, 10.859692113851242, 7.897310778980095, 21.72990005954096, 5.920471931677906, 5.920249476251248, 59.15282357684913, 4.932048219138397, 4.932008555766068, 4.932008928413813, 224.79646657748947, 235.55895311082125, 24.647363802109655, 519.6473789030318, 52.12599569238224, 354.68753358751843, 61.889730908387264, 363.8424293033621, 93.09001756432048, 60.70249677050166, 53.918869799867366, 1104.9338222083275, 1105.90737866689, 1105.9070527751962, 121.3742576069346, 64.0891632814606, 59.234250710243586, 58.263321978093664, 59.23446989933335, 43.699349450668784, 39.81575521909103, 42.7471700753786, 17.4840632094792, 14.571396211529898, 14.571395360524624, 14.571072827280021, 14.571071715978453, 12.629531942310349, 10.686954326839643, 9.716710052418076, 8.745818017538953, 8.745699575530109, 7.774773777632352, 7.774773696602576, 8.745564190068901, 6.803524661749796, 5.832760423018725, 5.832825869246285, 5.832613411371782, 4.860918681581039, 3.8908080845314026, 27.23827195582504, 96.3147010680504, 102.63593637589999, 215.4283982993561, 278.14500494924283, 50.03880558770013, 52.12599569238224, 60.70249677050166, 30.246074496531982, 59.15282357684913, 530.6925784391802, 121.94387303176687, 121.94427361813277, 108.28661060836036, 96.58024165275701, 77.06973189250341, 73.16766649171497, 59.509946037954975, 57.559140520264556, 53.65686822522324, 50.731942874306604, 50.73194279335496, 39.02395641299782, 39.0239458997168, 37.07289044226917, 36.09734759014361, 35.121815472808336, 118.03248494092006, 31.21946399440591, 31.219703218696782, 28.292908275755533, 27.31760650123769, 27.31812134282997, 23.415556762712658, 24.39059319517213, 17.562175797259076, 16.58685327688865, 14.635787151919137, 14.635784864049915, 14.63574605400929, 1202.9788813190262, 309.40340407077804, 93.09001756432048, 53.918869799867366, 363.8424293033621, 666.7342453282927, 235.55895311082125, 215.4283982993561], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -1.8841, -2.0885, -3.2512, -3.3027, -3.3181, -3.5506, -3.719, -3.9797, -4.0097, -4.1407, -4.291, -4.6549, -4.8479, -5.087, -5.1331, -5.3425, -5.5339, -5.5339, -5.7711, -5.699, -5.699, -5.9806, -6.2131, -6.2131, -6.2131, -6.2131, -6.3627, -1.7934, -6.5385, -6.5387, -2.7821, -6.2589, -4.6549, -3.5127, -3.5065, -3.9551, -4.3759, -5.7143, -3.5141, -5.7655, -0.8289, -3.2716, -3.622, -3.8445, -3.9222, -3.9089, -3.9636, -4.0217, -4.255, -4.274, -4.274, -4.333, -4.3958, -4.4179, -4.757, -4.9257, -4.9257, -4.9261, -5.0022, -5.1749, -5.3284, -5.5077, -5.5792, -5.6489, -5.7276, -6.01, -6.5814, -6.7945, -7.0661, -7.0671, -2.8766, -3.5608, -2.9252, -3.21, -4.7075, -4.9997, -4.9983, -4.6007, -2.0504, -2.7649, -2.886, -2.8861, -2.454, -3.1012, -3.2958, -3.4616, -4.0015, -4.0745, -4.1206, -4.3117, -4.6506, -5.0805, -5.2141, -5.3119, -5.3119, -5.4819, -5.5456, -5.6885, -5.8511, -5.9486, -6.2929, -5.3118, -6.6182, -6.6189, -4.333, -6.8318, -6.8318, -6.8318, -3.0212, -3.0365, -5.2629, -2.3368, -4.6309, -3.256, -4.6531, -3.6402, -4.7948, -5.0577, -5.2129, -1.386, -1.3851, -1.3851, -3.6002, -4.2456, -4.3245, -4.3412, -4.3248, -4.6336, -4.7283, -4.6829, -5.5774, -5.769, -5.769, -5.7691, -5.7691, -5.9208, -6.1004, -6.2031, -6.3181, -6.3183, -6.4482, -6.4482, -6.3364, -6.5994, -6.7741, -6.7742, -6.7744, -6.9892, -7.2602, -5.3753, -4.3555, -4.3412, -4.1731, -4.3294, -5.637, -5.7505, -5.9727, -6.239, -6.3071, -2.0349, -3.5104, -3.5105, -3.6299, -3.7451, -3.9732, -4.0256, -4.2345, -4.2684, -4.3394, -4.3988, -4.3988, -4.6634, -4.6636, -4.716, -4.7431, -4.7711, -3.5614, -4.8918, -4.8918, -4.9932, -5.029, -5.0303, -5.1879, -5.1472, -5.4878, -5.5471, -5.6789, -5.6789, -5.6791, -1.3072, -2.997, -4.2019, -4.9621, -4.1077, -3.97, -4.3906, -4.5935], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.7041, 1.7037, 1.6998, 1.6995, 1.6993, 1.6976, 1.6963, 1.6935, 1.6933, 1.6915, 1.6897, 1.6826, 1.6777, 1.6704, 1.6687, 1.6602, 1.6511, 1.6511, 1.6372, 1.6294, 1.6294, 1.6103, 1.601, 1.601, 1.601, 1.601, 1.5851, 1.5827, 1.5636, 1.5634, 1.4683, 1.5559, 1.3109, 0.9932, 0.6374, 0.7747, 0.8715, 1.2921, -0.7281, 0.5728, 1.6757, 1.6707, 1.6681, 1.6662, 1.6655, 1.6654, 1.6648, 1.6639, 1.6611, 1.6608, 1.6608, 1.6601, 1.6591, 1.6585, 1.6515, 1.6471, 1.6471, 1.6468, 1.6447, 1.639, 1.6321, 1.6246, 1.6176, 1.6169, 1.6122, 1.5921, 1.5314, 1.5004, 1.4515, 1.4507, 1.1307, 1.1689, 1.0567, 0.4153, 0.6034, 0.7728, 0.7548, -0.1374, 1.6212, 1.62, 1.6197, 1.6196, 1.6191, 1.6186, 1.6177, 1.6165, 1.6122, 1.6112, 1.6109, 1.6084, 1.6023, 1.5912, 1.5855, 1.5831, 1.5831, 1.5757, 1.5726, 1.5634, 1.5551, 1.5449, 1.5191, 1.488, 1.4819, 1.4812, 1.4654, 1.451, 1.451, 1.451, 1.4421, 1.3801, 1.411, 1.2886, 1.2939, 0.7513, 1.1001, 0.3416, 0.5501, 0.7149, 0.6781, 1.485, 1.485, 1.485, 1.4794, 1.4727, 1.4725, 1.4723, 1.4722, 1.4676, 1.4659, 1.4404, 1.4398, 1.4305, 1.4305, 1.4304, 1.4304, 1.4217, 1.4091, 1.4016, 1.3919, 1.3916, 1.3795, 1.3795, 1.3736, 1.3617, 1.3409, 1.3409, 1.3406, 1.3081, 1.2598, 1.1986, 0.9554, 0.9062, 0.3328, -0.079, 0.3287, 0.1743, -0.2002, 0.2301, -0.5087, 1.5695, 1.5646, 1.5645, 1.5639, 1.563, 1.5606, 1.5602, 1.5579, 1.5574, 1.5565, 1.5531, 1.5531, 1.5509, 1.5507, 1.5497, 1.5492, 1.5486, 1.5461, 1.5457, 1.5457, 1.5427, 1.542, 1.5407, 1.5372, 1.5372, 1.525, 1.5228, 1.5162, 1.5162, 1.5159, 1.4788, 1.1469, 1.1431, 0.9289, -0.1259, -0.5938, 0.026, -0.0876]}, \"token.table\": {\"Topic\": [2, 5, 3, 2, 3, 5, 3, 4, 2, 3, 3, 2, 3, 5, 5, 2, 1, 2, 3, 5, 1, 5, 4, 4, 4, 2, 5, 2, 4, 1, 1, 3, 1, 5, 3, 2, 3, 5, 2, 4, 5, 3, 4, 1, 1, 4, 2, 1, 1, 4, 3, 1, 2, 2, 3, 3, 3, 3, 4, 2, 5, 4, 2, 3, 2, 4, 4, 1, 2, 4, 5, 2, 3, 4, 2, 2, 3, 5, 1, 2, 4, 5, 1, 3, 5, 1, 2, 2, 1, 5, 4, 2, 2, 3, 1, 5, 1, 1, 4, 1, 1, 3, 1, 1, 2, 4, 5, 5, 5, 4, 1, 2, 3, 3, 1, 5, 2, 5, 4, 5, 1, 4, 1, 4, 1, 2, 4, 4, 1, 3, 3, 4, 4, 3, 4, 3, 5, 3, 1, 2, 3, 5, 2, 4, 3, 1, 5, 2, 5, 1, 2, 4, 5, 3, 5, 1, 4, 1, 5, 5, 2, 4, 1, 1, 1, 4, 2, 3, 5, 1, 4, 5, 4, 1, 5, 3, 5, 2, 1, 4, 2, 3, 5, 5, 3, 2, 4, 1, 5, 3, 5, 2, 3, 3, 3, 4, 5, 3, 3, 4, 1, 3, 4, 1, 3, 4, 5, 2, 1, 4, 3, 5, 2, 2], \"Freq\": [0.953500029625872, 0.9855723484445221, 0.9401795273424716, 0.5807928965430355, 0.41726868295324876, 0.9877579842627777, 0.9662028042579607, 0.9991795165812314, 0.16459333442078702, 0.8363120775975125, 0.9281968389203394, 0.07418553124067596, 0.38947403901354877, 0.5192987186847318, 0.9646193725179721, 0.9994102363896675, 0.9135706277961138, 0.9841617326762707, 0.9967184067389626, 0.0030112338572174098, 0.3425948086070566, 0.6528693522511834, 0.983996341834373, 0.9991548614138165, 0.999179811022165, 0.9816393578092977, 0.9986949535996581, 0.9582381429433031, 0.9795117481860576, 0.9853782674740563, 0.8462303749058454, 0.8110286011818764, 0.8882297622134793, 0.9737610875551098, 0.9953549033840183, 0.9858481065260147, 0.34375329210663885, 0.6552797130782804, 0.9533410587197855, 0.9607864474182803, 0.9922565152908307, 0.9945362676766021, 0.9608078439863676, 0.8882469271074019, 0.9982353347628046, 0.8818958258110969, 0.9858886407423613, 0.9924575513127366, 0.6794726532872604, 0.31975183684106373, 0.8445272704101753, 0.3948363786982575, 0.6038674027149821, 0.28288413637400595, 0.7158700593954437, 0.9816743796799787, 0.9490885822574423, 0.9908589546061, 0.935720289819673, 0.8208407350151385, 0.9680592971147275, 0.9783170280168945, 0.9801334872365496, 0.8863776791754954, 0.9881742513908764, 0.9003477400382582, 0.9501539767913848, 0.07342609704622946, 0.03671304852311473, 0.7342609704622947, 0.14685219409245892, 0.41184467410817827, 0.39537088714385116, 0.18121165660759844, 0.7694218655775134, 0.5386947321544526, 0.2775926936102026, 0.18414564823647103, 0.06229578593366289, 0.3426268226351459, 0.5918099663697974, 0.9696003262454872, 0.984419812964374, 0.9527780593113203, 0.9881184700386122, 0.9993120126032863, 0.9822649817343598, 0.9864175718290794, 0.9794467192076569, 0.9565621013330485, 0.9147228977274302, 0.9873396755122736, 0.9910808544190147, 0.992819944242736, 0.9911741537124833, 0.9861199479194314, 0.9792942295397893, 0.991317344527973, 0.972314032288744, 0.8882296787108753, 0.09203907954108877, 0.8743712556403433, 0.8882297281414863, 0.6789354197229893, 0.28288975821791223, 0.9791632257444907, 0.98557234687187, 0.9543027438835816, 0.9939921287954196, 0.9830055000612613, 0.31905656720705655, 0.1450257123668439, 0.49308742204726924, 0.9976409244285552, 0.9470158313348049, 0.9883735604280228, 0.9625495125766141, 0.9840412227462907, 0.9791596024843089, 0.9902858083840271, 0.9302271755338434, 0.900347749421808, 0.9947066005949151, 0.9262394320143661, 0.8702178169470622, 0.9534940056573828, 0.9607865035305684, 0.857227048151631, 0.9940030820091131, 0.9853604095878196, 0.9837584000808299, 0.8572486546513703, 0.9969164993111915, 0.7098185753295304, 0.26858000147603855, 0.9616198852675866, 0.9609316203247464, 0.9616198770525852, 0.8462114048061773, 0.403944234900721, 0.5978374676530671, 0.9922597748595291, 0.9881740310149614, 0.8572174297817838, 0.8110220789160855, 0.08811459755949709, 0.9119029577619652, 0.988894698782032, 0.9822529625528957, 0.9368631090529086, 0.9832189647885103, 0.016944487790806737, 0.9743080479713874, 0.8114458065607864, 0.1622891613121573, 0.9683750023800047, 0.9147494462489301, 0.9470158680940862, 0.9839859083357824, 0.9737608252182045, 0.9238752407919031, 0.9147352857149899, 0.9368629585900214, 0.970365125314024, 0.43844292349211206, 0.555361036423342, 0.8552480272096422, 0.9978442757445285, 0.9914309107652403, 0.8888398214986194, 0.1269771173569456, 0.9517491951116204, 0.7710480534691577, 0.9909709185819109, 0.9679893992778039, 0.8110285399029971, 0.9565594152661773, 0.9727512599850787, 0.9582377737694703, 0.9608077707078057, 0.9964671433052532, 0.9802592537466369, 0.9710599732184384, 0.9565595647957629, 0.995312137813661, 0.9889244757615762, 0.822889717360789, 0.8849102984195606, 0.11548829318356978, 0.8445590038151639, 0.9609389836217425, 0.9476708014793702, 0.9716463366832852, 0.9208364192245627, 0.13224856668453425, 0.297559275040202, 0.595118550080404, 0.9978442324633552, 0.8621735517619495, 0.1352429100803058, 0.9835167262168533, 0.023393361437415418, 0.9591278189340321, 0.4920428357486276, 0.004641913544798373, 0.3156501210462894, 0.1903184553367333, 0.9646377154217392, 0.7873590972448494, 0.20852432712420668, 0.7853660306979067, 0.2122610893778126, 0.9534999894521098, 0.7693371128575971], \"Term\": [\"abus\", \"accid\", \"act\", \"aggrav\", \"aggrav\", \"alprazolam\", \"arm\", \"arrest\", \"assault\", \"assault\", \"assign\", \"attempt\", \"attempt\", \"attempt\", \"attend\", \"batteri\", \"bill\", \"bodili\", \"burglari\", \"burglari\", \"cannabi\", \"cannabi\", \"carri\", \"case\", \"charg\", \"child\", \"cocain\", \"commit\", \"conceal\", \"conduct\", \"consider\", \"construct\", \"contraband\", \"control\", \"convey\", \"convict\", \"crimin\", \"crimin\", \"cruelti\", \"culpabl\", \"damag\", \"dead\", \"deal\", \"defraud\", \"degre\", \"delinqu\", \"deliv\", \"deliveri\", \"disord\", \"disord\", \"display\", \"domest\", \"domest\", \"drive\", \"drive\", \"driver\", \"dwel\", \"dwell\", \"ecstasi\", \"elder\", \"elud\", \"enforc\", \"enhanc\", \"ent\", \"evid\", \"expir\", \"expos\", \"failur\", \"failur\", \"failur\", \"failur\", \"fals\", \"fals\", \"fals\", \"famili\", \"feloni\", \"feloni\", \"feloni\", \"firearm\", \"firearm\", \"firearm\", \"flee\", \"forg\", \"fraud\", \"gram\", \"grand\", \"great\", \"harm\", \"heroin\", \"hydromorphon\", \"ident\", \"imprison\", \"influenc\", \"info\", \"injunct\", \"injuri\", \"instrument\", \"intent\", \"intox\", \"introduc\", \"item\", \"item\", \"jail\", \"lascivi\", \"lascivi\", \"law\", \"leav\", \"leo\", \"less\", \"level\", \"lewd\", \"lewd\", \"lewd\", \"licens\", \"loiter\", \"methamphetamin\", \"methylenediox\", \"methylenedioxymethcath\", \"minor\", \"mischief\", \"molest\", \"month\", \"motor\", \"name\", \"near\", \"neglect\", \"neglig\", \"obey\", \"obstruct\", \"occupi\", \"offens\", \"offer\", \"offic\", \"oper\", \"oper\", \"ownership\", \"oxycodon\", \"pawn\", \"pay\", \"person\", \"person\", \"petit\", \"physic\", \"polic\", \"poss\", \"possess\", \"possess\", \"pregnant\", \"prescript\", \"pretrial\", \"prior\", \"properti\", \"properti\", \"prostitut\", \"prostitut\", \"prot\", \"protect\", \"prowl\", \"public\", \"pyrrolidinovalerophenon\", \"reckless\", \"regist\", \"releas\", \"repeat\", \"resist\", \"resist\", \"return\", \"revok\", \"robberi\", \"sale\", \"sale\", \"scene\", \"secur\", \"sell\", \"servant\", \"site\", \"snatch\", \"solicit\", \"stalk\", \"stolen\", \"strangul\", \"structur\", \"substanc\", \"sudden\", \"suspend\", \"tamper\", \"tetrahydrocannabinol\", \"theft\", \"theft\", \"throw\", \"tool\", \"toward\", \"trespass\", \"unattend\", \"unlaw\", \"unlaw\", \"unlaw\", \"unoccupi\", \"use\", \"use\", \"utter\", \"valid\", \"valid\", \"vehicl\", \"vehicl\", \"vehicl\", \"vehicl\", \"victim\", \"violenc\", \"violenc\", \"weapon\", \"weapon\", \"wit\", \"yrs\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3, 4, 5]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el138349971444648379584889\", ldavis_el138349971444648379584889_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.2.2/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el138349971444648379584889\", ldavis_el138349971444648379584889_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.2.2/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el138349971444648379584889\", ldavis_el138349971444648379584889_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "0     -0.248000 -0.123399       1        1  18.165289\n",
       "1      0.278194  0.002663       2        1  18.704818\n",
       "2      0.279709 -0.027695       3        1  19.721858\n",
       "3     -0.155911  0.385750       4        1  22.629155\n",
       "4     -0.153993 -0.237319       5        1  20.778881, topic_info=       Term         Freq        Total Category  logprob  loglift\n",
       "3   batteri  1593.000000  1593.000000  Default  30.0000  30.0000\n",
       "10   arrest  1105.000000  1105.000000  Default  29.0000  29.0000\n",
       "12    charg  1105.000000  1105.000000  Default  28.0000  28.0000\n",
       "11     case  1104.000000  1104.000000  Default  27.0000  27.0000\n",
       "8   possess  1202.000000  1202.000000  Default  26.0000  26.0000\n",
       "..      ...          ...          ...      ...      ...      ...\n",
       "48  attempt    28.365148    53.918870   Topic5  -4.9621   0.9289\n",
       "5    feloni    66.661772   363.842429   Topic5  -4.1077  -0.1259\n",
       "25    theft    76.501954   666.734245   Topic5  -3.9700  -0.5938\n",
       "55   weapon    50.233395   235.558953   Topic5  -4.3906   0.0260\n",
       "73   vehicl    41.008905   215.428398   Topic5  -4.5935  -0.0876\n",
       "\n",
       "[227 rows x 6 columns], token_table=      Topic      Freq     Term\n",
       "term                          \n",
       "126       2  0.953500     abus\n",
       "123       5  0.985572    accid\n",
       "266       3  0.940180      act\n",
       "0         2  0.580793   aggrav\n",
       "0         3  0.417269   aggrav\n",
       "...     ...       ...      ...\n",
       "65        4  0.208524  violenc\n",
       "55        3  0.785366   weapon\n",
       "55        5  0.212261   weapon\n",
       "167       2  0.953500      wit\n",
       "190       2  0.769337      yrs\n",
       "\n",
       "[214 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualize_model(model, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train second LDA model\n",
    "\n",
    "# set training parameters \n",
    "num_topics = 5\n",
    "chunksize = 10000\n",
    "passes = 20\n",
    "iterations = 400\n",
    "eval_every = 1\n",
    "\n",
    "temp = dictionary[0]\n",
    "id2word = dictionary.id2token\n",
    "\n",
    "model2 = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every,\n",
    "    random_state=25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.166*\"theft\" + 0.152*\"grand\" + 0.124*\"degre\" + 0.062*\"violenc\" + '\n",
      "  '0.039*\"deliveri\" + 0.037*\"intent\" + 0.036*\"sell\" + 0.030*\"cannabi\" + '\n",
      "  '0.030*\"vehicl\" + 0.030*\"possess\"'),\n",
      " (1,\n",
      "  '0.437*\"batteri\" + 0.056*\"aggrav\" + 0.054*\"feloni\" + 0.040*\"drive\" + '\n",
      "  '0.038*\"influenc\" + 0.028*\"domest\" + 0.027*\"strangul\" + 0.021*\"tamper\" + '\n",
      "  '0.020*\"harm\" + 0.020*\"deliv\"'),\n",
      " (2,\n",
      "  '0.129*\"licens\" + 0.097*\"drive\" + 0.086*\"burglari\" + 0.063*\"suspend\" + '\n",
      "  '0.056*\"revok\" + 0.056*\"unoccupi\" + 0.049*\"assault\" + 0.048*\"weapon\" + '\n",
      "  '0.045*\"dead\" + 0.039*\"aggrav\"'),\n",
      " (3,\n",
      "  '0.250*\"arrest\" + 0.250*\"charg\" + 0.250*\"case\" + 0.027*\"offic\" + '\n",
      "  '0.015*\"vehicl\" + 0.014*\"level\" + 0.013*\"law\" + 0.013*\"minor\" + '\n",
      "  '0.013*\"violenc\" + 0.013*\"resist\"'),\n",
      " (4,\n",
      "  '0.271*\"possess\" + 0.131*\"cocain\" + 0.050*\"cannabi\" + 0.030*\"petit\" + '\n",
      "  '0.030*\"damag\" + 0.028*\"properti\" + 0.027*\"gram\" + 0.024*\"less\" + '\n",
      "  '0.019*\"theft\" + 0.019*\"injuri\"')]\n"
     ]
    }
   ],
   "source": [
    "pprint(model.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_distr_to_cols(model, tokenized_docs):\n",
    "    topics = [model.get_document_topics(dictionary.doc2bow(doc), minimum_probability=0) for doc in tokenized_docs]\n",
    "    rows = [[topic_distr[i][1] for i in range(len(topic_distr))] for topic_distr in topics]\n",
    "    columns = [[row[i] for row in rows] for i in range(len(row))] \n",
    "    return columns\n",
    "    \n",
    "def get_max_topics(model, tokenized_docs):\n",
    "    topics = [model.get_document_topics(dictionary.doc2bow(doc), minimum_probability=0) for doc in tokenized_docs]\n",
    "    rows = [[topic_distr[i][1] for i in range(len(topic_distr))] for topic_distr in topics]\n",
    "    max_topics = [np.argmax(row) + 1 for row in rows]\n",
    "    return max_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Topic Distribution Dataframe for First Offense Charge Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02523719, 0.88318557, 0.027123129, 0.031303093, 0.033150993]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>race</th>\n",
       "      <th>charge description</th>\n",
       "      <th>tokenized description</th>\n",
       "      <th>max topic</th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>t3</th>\n",
       "      <th>t4</th>\n",
       "      <th>t5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>miguel hernandez</td>\n",
       "      <td>miguel hernandez</td>\n",
       "      <td>Aggravated Assault w/Firearm</td>\n",
       "      <td>[aggrav, assault, firearm]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.025237</td>\n",
       "      <td>0.883186</td>\n",
       "      <td>0.027123</td>\n",
       "      <td>0.031303</td>\n",
       "      <td>0.033151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>Felony Battery w/Prior Convict</td>\n",
       "      <td>[feloni, batteri, prior, convict]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.019687</td>\n",
       "      <td>0.908891</td>\n",
       "      <td>0.021150</td>\n",
       "      <td>0.024409</td>\n",
       "      <td>0.025863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ed philo</td>\n",
       "      <td>ed philo</td>\n",
       "      <td>Possession of Cocaine</td>\n",
       "      <td>[possess, cocain]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.035144</td>\n",
       "      <td>0.052206</td>\n",
       "      <td>0.037754</td>\n",
       "      <td>0.043574</td>\n",
       "      <td>0.831321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>marcu brown</td>\n",
       "      <td>marcu brown</td>\n",
       "      <td>Possession of Cannabis</td>\n",
       "      <td>[possess, cannabi]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.035146</td>\n",
       "      <td>0.052206</td>\n",
       "      <td>0.037754</td>\n",
       "      <td>0.043574</td>\n",
       "      <td>0.831319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>bouthy pierrelouis</td>\n",
       "      <td>bouthy pierrelouis</td>\n",
       "      <td>arrest case no charge</td>\n",
       "      <td>[arrest, case, charg]</td>\n",
       "      <td>4</td>\n",
       "      <td>0.025237</td>\n",
       "      <td>0.037489</td>\n",
       "      <td>0.027111</td>\n",
       "      <td>0.877013</td>\n",
       "      <td>0.033151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7209</th>\n",
       "      <td>10996</td>\n",
       "      <td>steven butler</td>\n",
       "      <td>steven butler</td>\n",
       "      <td>Deliver Cannabis</td>\n",
       "      <td>[deliveri, cannabi]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.820242</td>\n",
       "      <td>0.052206</td>\n",
       "      <td>0.037754</td>\n",
       "      <td>0.043574</td>\n",
       "      <td>0.046224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7210</th>\n",
       "      <td>10997</td>\n",
       "      <td>malcolm simmons</td>\n",
       "      <td>malcolm simmons</td>\n",
       "      <td>Leaving the Scene of Accident</td>\n",
       "      <td>[leav, scene, accid]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.025237</td>\n",
       "      <td>0.037489</td>\n",
       "      <td>0.027111</td>\n",
       "      <td>0.031291</td>\n",
       "      <td>0.878872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7211</th>\n",
       "      <td>10999</td>\n",
       "      <td>winston gregory</td>\n",
       "      <td>winston gregory</td>\n",
       "      <td>Aggravated Battery / Pregnant</td>\n",
       "      <td>[aggrav, batteri, pregnant]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.025237</td>\n",
       "      <td>0.883209</td>\n",
       "      <td>0.027113</td>\n",
       "      <td>0.031290</td>\n",
       "      <td>0.033151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7212</th>\n",
       "      <td>11000</td>\n",
       "      <td>farrah jean</td>\n",
       "      <td>farrah jean</td>\n",
       "      <td>Battery on Law Enforc Officer</td>\n",
       "      <td>[batteri, law, enforc, offic]</td>\n",
       "      <td>4</td>\n",
       "      <td>0.019687</td>\n",
       "      <td>0.249165</td>\n",
       "      <td>0.021149</td>\n",
       "      <td>0.684139</td>\n",
       "      <td>0.025861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7213</th>\n",
       "      <td>11001</td>\n",
       "      <td>florencia sanmartin</td>\n",
       "      <td>florencia sanmartin</td>\n",
       "      <td>Possession of Ethylone</td>\n",
       "      <td>[possess, ethylon]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.035147</td>\n",
       "      <td>0.052209</td>\n",
       "      <td>0.037757</td>\n",
       "      <td>0.043577</td>\n",
       "      <td>0.831310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7185 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                 name                 race  \\\n",
       "0         1     miguel hernandez     miguel hernandez   \n",
       "1         3          kevon dixon          kevon dixon   \n",
       "2         4             ed philo             ed philo   \n",
       "3         5          marcu brown          marcu brown   \n",
       "4         6   bouthy pierrelouis   bouthy pierrelouis   \n",
       "...     ...                  ...                  ...   \n",
       "7209  10996        steven butler        steven butler   \n",
       "7210  10997      malcolm simmons      malcolm simmons   \n",
       "7211  10999      winston gregory      winston gregory   \n",
       "7212  11000          farrah jean          farrah jean   \n",
       "7213  11001  florencia sanmartin  florencia sanmartin   \n",
       "\n",
       "                  charge description              tokenized description  \\\n",
       "0       Aggravated Assault w/Firearm         [aggrav, assault, firearm]   \n",
       "1     Felony Battery w/Prior Convict  [feloni, batteri, prior, convict]   \n",
       "2              Possession of Cocaine                  [possess, cocain]   \n",
       "3             Possession of Cannabis                 [possess, cannabi]   \n",
       "4              arrest case no charge              [arrest, case, charg]   \n",
       "...                              ...                                ...   \n",
       "7209                Deliver Cannabis                [deliveri, cannabi]   \n",
       "7210   Leaving the Scene of Accident               [leav, scene, accid]   \n",
       "7211   Aggravated Battery / Pregnant        [aggrav, batteri, pregnant]   \n",
       "7212   Battery on Law Enforc Officer      [batteri, law, enforc, offic]   \n",
       "7213          Possession of Ethylone                 [possess, ethylon]   \n",
       "\n",
       "      max topic        t1        t2        t3        t4        t5  \n",
       "0             2  0.025237  0.883186  0.027123  0.031303  0.033151  \n",
       "1             2  0.019687  0.908891  0.021150  0.024409  0.025863  \n",
       "2             5  0.035144  0.052206  0.037754  0.043574  0.831321  \n",
       "3             5  0.035146  0.052206  0.037754  0.043574  0.831319  \n",
       "4             4  0.025237  0.037489  0.027111  0.877013  0.033151  \n",
       "...         ...       ...       ...       ...       ...       ...  \n",
       "7209          1  0.820242  0.052206  0.037754  0.043574  0.046224  \n",
       "7210          5  0.025237  0.037489  0.027111  0.031291  0.878872  \n",
       "7211          2  0.025237  0.883209  0.027113  0.031290  0.033151  \n",
       "7212          4  0.019687  0.249165  0.021149  0.684139  0.025861  \n",
       "7213          5  0.035147  0.052209  0.037757  0.043577  0.831310  \n",
       "\n",
       "[7185 rows x 11 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_stemmed = stem_tokens(tokenized_descs)\n",
    "cols = topic_distr_to_cols(model, tokenized_stemmed)\n",
    "max_topics = get_max_topics(model, tokenized_stemmed)\n",
    "d = {\n",
    "     'id': compas_df_charge_filt['id'], \n",
    "     'name': compas_df_charge_filt['name'], \n",
    "     'race': compas_df_charge_filt['name'], \n",
    "     'charge description': compas_df_charge_filt['c_charge_desc'], \n",
    "     'tokenized description': tokenized_stemmed,\n",
    "     'max topic': max_topics, \n",
    "     't1': cols[0], 't2': cols[1], 't3': cols[2], 't4': cols[3], 't5': cols[4]}\n",
    "compas_df_topics = pd.DataFrame(data=d)\n",
    "compas_df_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>c_charge_desc</th>\n",
       "      <th>r_charge_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>Felony Battery w/Prior Convict</td>\n",
       "      <td>Felony Battery (Dom Strang)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ed philo</td>\n",
       "      <td>Possession of Cocaine</td>\n",
       "      <td>Driving Under The Influence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>edward riddle</td>\n",
       "      <td>Possession Burglary Tools</td>\n",
       "      <td>Poss of Firearm by Convic Felo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bo bradac</td>\n",
       "      <td>Insurance Fraud</td>\n",
       "      <td>Battery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ellyaher lanza</td>\n",
       "      <td>Battery</td>\n",
       "      <td>Driving License Suspended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7201</th>\n",
       "      <td>kyle miller</td>\n",
       "      <td>Possession of Cocaine</td>\n",
       "      <td>Operating W/O Valid License</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7205</th>\n",
       "      <td>christopher tun</td>\n",
       "      <td>arrest case no charge</td>\n",
       "      <td>Assault</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7206</th>\n",
       "      <td>alexander vega</td>\n",
       "      <td>Grand Theft (Motor Vehicle)</td>\n",
       "      <td>Possess Cannabis/20 Grams Or Less</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7207</th>\n",
       "      <td>jarred payne</td>\n",
       "      <td>Possess Cannabis/20 Grams Or Less</td>\n",
       "      <td>Possession of Cannabis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7213</th>\n",
       "      <td>florencia sanmartin</td>\n",
       "      <td>Possession of Ethylone</td>\n",
       "      <td>Operating W/O Valid License</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3413 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name                      c_charge_desc  \\\n",
       "1             kevon dixon     Felony Battery w/Prior Convict   \n",
       "2                ed philo              Possession of Cocaine   \n",
       "6           edward riddle          Possession Burglary Tools   \n",
       "9               bo bradac                    Insurance Fraud   \n",
       "11         ellyaher lanza                            Battery   \n",
       "...                   ...                                ...   \n",
       "7201          kyle miller              Possession of Cocaine   \n",
       "7205      christopher tun              arrest case no charge   \n",
       "7206       alexander vega        Grand Theft (Motor Vehicle)   \n",
       "7207         jarred payne  Possess Cannabis/20 Grams Or Less   \n",
       "7213  florencia sanmartin             Possession of Ethylone   \n",
       "\n",
       "                          r_charge_desc  \n",
       "1           Felony Battery (Dom Strang)  \n",
       "2           Driving Under The Influence  \n",
       "6        Poss of Firearm by Convic Felo  \n",
       "9                               Battery  \n",
       "11            Driving License Suspended  \n",
       "...                                 ...  \n",
       "7201        Operating W/O Valid License  \n",
       "7205                            Assault  \n",
       "7206  Possess Cannabis/20 Grams Or Less  \n",
       "7207             Possession of Cannabis  \n",
       "7213        Operating W/O Valid License  \n",
       "\n",
       "[3413 rows x 3 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check c_charge_desc against r_charge_desc\n",
    "idx = compas_df['r_charge_desc'].isna() == False\n",
    "compas_df.loc[idx][['name','c_charge_desc','r_charge_desc']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Topic Distribution Dataframe for Second Offense Charge Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>race</th>\n",
       "      <th>charge description</th>\n",
       "      <th>tokenized desc</th>\n",
       "      <th>max topic</th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>t3</th>\n",
       "      <th>t4</th>\n",
       "      <th>t5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>African-American</td>\n",
       "      <td>Felony Battery w/Prior Convict</td>\n",
       "      <td>[feloni, batteri, domest, strangul]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.019687</td>\n",
       "      <td>0.908891</td>\n",
       "      <td>0.021150</td>\n",
       "      <td>0.024409</td>\n",
       "      <td>0.025863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ed philo</td>\n",
       "      <td>African-American</td>\n",
       "      <td>Possession of Cocaine</td>\n",
       "      <td>[drive, influenc]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.035144</td>\n",
       "      <td>0.837351</td>\n",
       "      <td>0.037766</td>\n",
       "      <td>0.043574</td>\n",
       "      <td>0.046165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>edward riddle</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Possession Burglary Tools</td>\n",
       "      <td>[possess, firearm, convict, felon]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.019688</td>\n",
       "      <td>0.469167</td>\n",
       "      <td>0.021150</td>\n",
       "      <td>0.024426</td>\n",
       "      <td>0.465570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13</td>\n",
       "      <td>bo bradac</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Insurance Fraud</td>\n",
       "      <td>[batteri]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.057858</td>\n",
       "      <td>0.732249</td>\n",
       "      <td>0.062155</td>\n",
       "      <td>0.071737</td>\n",
       "      <td>0.076001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15</td>\n",
       "      <td>ellyaher lanza</td>\n",
       "      <td>African-American</td>\n",
       "      <td>Battery</td>\n",
       "      <td>[drive, licens, suspend]</td>\n",
       "      <td>3</td>\n",
       "      <td>0.025237</td>\n",
       "      <td>0.037505</td>\n",
       "      <td>0.872817</td>\n",
       "      <td>0.031290</td>\n",
       "      <td>0.033151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>19</td>\n",
       "      <td>craig gilbert</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>arrest case no charge</td>\n",
       "      <td>[grand, theft, motor, vehicl]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.899330</td>\n",
       "      <td>0.029244</td>\n",
       "      <td>0.021149</td>\n",
       "      <td>0.024412</td>\n",
       "      <td>0.025864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20</td>\n",
       "      <td>samuel seraphin</td>\n",
       "      <td>African-American</td>\n",
       "      <td>Felony Driving While Lic Suspd</td>\n",
       "      <td>[crimin, mischief]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.035144</td>\n",
       "      <td>0.052206</td>\n",
       "      <td>0.037757</td>\n",
       "      <td>0.043575</td>\n",
       "      <td>0.831318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>23</td>\n",
       "      <td>neil heckart</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Driving While License Revoked</td>\n",
       "      <td>[grand, theft, degre]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.870958</td>\n",
       "      <td>0.037489</td>\n",
       "      <td>0.027111</td>\n",
       "      <td>0.031290</td>\n",
       "      <td>0.033152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>24</td>\n",
       "      <td>michael lux</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Possession Of Heroin</td>\n",
       "      <td>[possess, cocain]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.035144</td>\n",
       "      <td>0.052206</td>\n",
       "      <td>0.037754</td>\n",
       "      <td>0.043574</td>\n",
       "      <td>0.831321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>25</td>\n",
       "      <td>columbus wilson</td>\n",
       "      <td>African-American</td>\n",
       "      <td>arrest case no charge</td>\n",
       "      <td>[possess, cocain, intent, deliveri, sell]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.587760</td>\n",
       "      <td>0.023973</td>\n",
       "      <td>0.017336</td>\n",
       "      <td>0.020009</td>\n",
       "      <td>0.350922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id             name              race              charge description  \\\n",
       "1    3      kevon dixon  African-American  Felony Battery w/Prior Convict   \n",
       "2    4         ed philo  African-American           Possession of Cocaine   \n",
       "6    8    edward riddle         Caucasian       Possession Burglary Tools   \n",
       "9   13        bo bradac         Caucasian                 Insurance Fraud   \n",
       "11  15   ellyaher lanza  African-American                         Battery   \n",
       "14  19    craig gilbert         Caucasian           arrest case no charge   \n",
       "15  20  samuel seraphin  African-American  Felony Driving While Lic Suspd   \n",
       "18  23     neil heckart         Caucasian   Driving While License Revoked   \n",
       "19  24      michael lux         Caucasian            Possession Of Heroin   \n",
       "20  25  columbus wilson  African-American           arrest case no charge   \n",
       "\n",
       "                               tokenized desc  max topic        t1        t2  \\\n",
       "1         [feloni, batteri, domest, strangul]          2  0.019687  0.908891   \n",
       "2                           [drive, influenc]          2  0.035144  0.837351   \n",
       "6          [possess, firearm, convict, felon]          2  0.019688  0.469167   \n",
       "9                                   [batteri]          2  0.057858  0.732249   \n",
       "11                   [drive, licens, suspend]          3  0.025237  0.037505   \n",
       "14              [grand, theft, motor, vehicl]          1  0.899330  0.029244   \n",
       "15                         [crimin, mischief]          5  0.035144  0.052206   \n",
       "18                      [grand, theft, degre]          1  0.870958  0.037489   \n",
       "19                          [possess, cocain]          5  0.035144  0.052206   \n",
       "20  [possess, cocain, intent, deliveri, sell]          1  0.587760  0.023973   \n",
       "\n",
       "          t3        t4        t5  \n",
       "1   0.021150  0.024409  0.025863  \n",
       "2   0.037766  0.043574  0.046165  \n",
       "6   0.021150  0.024426  0.465570  \n",
       "9   0.062155  0.071737  0.076001  \n",
       "11  0.872817  0.031290  0.033151  \n",
       "14  0.021149  0.024412  0.025864  \n",
       "15  0.037757  0.043575  0.831318  \n",
       "18  0.027111  0.031290  0.033152  \n",
       "19  0.037754  0.043574  0.831321  \n",
       "20  0.017336  0.020009  0.350922  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_tokenized_stemmed = stem_tokens(r_tokenized_descs)\n",
    "r_cols = topic_distr_to_cols(model, r_tokenized_stemmed)\n",
    "r_max_topics = get_max_topics(model, r_tokenized_stemmed)\n",
    "d = {\n",
    "     'id': r_compas_df_charge_filt['id'], \n",
    "     'name': r_compas_df_charge_filt['name'], \n",
    "     'race': r_compas_df_charge_filt['race'], \n",
    "     'charge description': r_compas_df_charge_filt['c_charge_desc'], \n",
    "     'tokenized desc': r_tokenized_stemmed,\n",
    "     'max topic': r_max_topics, \n",
    "     't1': r_cols[0], 't2': r_cols[1], 't3': r_cols[2], 't4': r_cols[3], 't5': r_cols[4]\n",
    "    }\n",
    "r_compas_df_topics = pd.DataFrame(data=d)\n",
    "r_compas_df_topics[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
