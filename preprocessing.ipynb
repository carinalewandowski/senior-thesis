{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling: Cleaning/Pre-Processing\n",
    "\n",
    "### References/Useful Links:\n",
    "NLTK Documentation: https://www.nltk.org/api/nltk.html?highlight=nltk%20text%20text  \n",
    "Tutorial on Tokenization: https://www.guru99.com/tokenize-words-sentences-nltk.html  \n",
    "NLTK List of English Stopwords: https://gist.github.com/sebleier/554280  \n",
    "Regular Expression Documentation: https://docs.python.org/3/library/re.html  \n",
    "See also LDA_tests.ipynb for tutorials on prepping texts for LDA.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import NLP libraries for preprocessing\n",
    "from nltk.corpus.reader.wordnet import NOUN\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Data\n",
    "1. Convert dataframe column with charge descriptions to list.\n",
    "2. Pad with space (' ') on front and back of each description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_charge_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aggravated Assault w/Firearm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Felony Battery w/Prior Convict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Possession of Cocaine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Possession of Cannabis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arrest case no charge</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    c_charge_desc\n",
       "0    Aggravated Assault w/Firearm\n",
       "1  Felony Battery w/Prior Convict\n",
       "2           Possession of Cocaine\n",
       "3          Possession of Cannabis\n",
       "4           arrest case no charge"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compas_path = 'compas-scores-two-years.csv'\n",
    "url = 'https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv'\n",
    "compas_df = pd.read_csv(url)\n",
    "# sample charge descriptions\n",
    "compas_df[['c_charge_desc']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' Aggravated Assault w/Firearm ',\n",
       " ' Felony Battery w/Prior Convict ',\n",
       " ' Possession of Cocaine ',\n",
       " ' Possession of Cannabis ',\n",
       " ' arrest case no charge ',\n",
       " ' Battery ',\n",
       " ' Possession Burglary Tools ',\n",
       " ' arrest case no charge ',\n",
       " ' Battery ',\n",
       " ' Insurance Fraud ']"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get non-NaN charge descriptions as a list\n",
    "compas_df_charge_filt = compas_df[compas_df['c_charge_desc'].isna() == False]\n",
    "charge_descs = list(compas_df_charge_filt['c_charge_desc'])\n",
    "charge_descs = [' ' + desc + ' ' for desc in charge_descs]\n",
    "print(len(charge_descs))\n",
    "charge_descs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Word Replacement Mappings\n",
    "\n",
    "Build dictionary with replacement word and all its mispellings as they appear in charge descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary with replacement (str) --> mispellings (list of str) mapping\n",
    "replacement_map = {\n",
    "    ' accident ': [' acc ', ' accd '],\n",
    "    ' aggravated ': [' agg ', ' aggr '],\n",
    "    ' alter ': [' alt '],\n",
    "    ' ammunition ': [' amm '],\n",
    "    ' amphetamine ': [' amp '],\n",
    "    ' attempt ': [' att ', ' attmp '],\n",
    "    ' attend ': [' attnd '],\n",
    "    ' battery ': [' batt ', ' bat '],\n",
    "    ' beverage ': [' bev '],\n",
    "    ' bodily ': [' bod '],\n",
    "    ' burglary ': ['burg ', ' burgl '],\n",
    "    ' business ': [' busn '],\n",
    "    ' cancel ': [' can '],\n",
    "    ' counterfeit ': [' cntrft ', ' conterfeit ', ' contrft ', ' countrfeit'],\n",
    "    ' commit ': [' com '],\n",
    "    ' communication ': [' communic '],\n",
    "    ' compensation ': [' compensatn '],\n",
    "    ' conspiracy ': [' consp '],\n",
    "    ' control ': [' cont ', ' contr '],\n",
    "    ' conveyance ': [' conv ', ' conve '],\n",
    "    ' control ': [' cont ', ' contr '],\n",
    "    ' convict ': [' convic '],\n",
    "    ' credit ': [' cred '],\n",
    "    ' criminal ': [' crim '],\n",
    "    ' cruelty ': [' crlty '],\n",
    "    ' custody ': [' cust '],\n",
    "    ' dangerous ': [' dang '],\n",
    "    ' degree ': [' deg '],\n",
    "    ' delinquency ': [' delinq '],\n",
    "    ' delivery ': [' deliv ', ' del '],\n",
    "    ' device ': [' dev '],\n",
    "    ' display ': [' disply '],\n",
    "    ' disqualified ': [' disqul '],\n",
    "    ' disorderly conduct ': [' doc '],\n",
    "    ' dollars ': [' dols '],\n",
    "    ' d u i ': [' dui '],\n",
    "    ' domestic ': [' dom ', ' dome '],\n",
    "    ' drive ': [' driv ', ' drivg '],\n",
    "    ' dwelling ': [' dwell '],\n",
    "    ' elderly ': [' elderlly '],\n",
    "    ' employee ': [' emplyee '],\n",
    "    ' enforcement ': [' enfor ', ' enforc '],\n",
    "    ' exhibition ': [' exhib '],\n",
    "    ' extinguisher ': [' extinquisher '],\n",
    "    ' facilitate ': [' fac '],\n",
    "    ' failure ': [' fail '],\n",
    "    ' family ': [' faml '],\n",
    "    ' felony ': [' fel '],\n",
    "    ' felon ': [' felo '],\n",
    "    ' firearm ': [' f arm '],\n",
    "    ' fraud ': [' frd ', ' fraudul'],\n",
    "    ' gambling ': [' gamb '],\n",
    "    ' gram ': [' g '], # check\n",
    "    ' great ': [' grt '],\n",
    "    ' informant ': ['informnt '],\n",
    "    ' injunction ': [' inj ', ' injunc ', ' injunct ', ' injunctn '],\n",
    "    ' instrument ': [' inst '],\n",
    "    ' intent ': [' int '],\n",
    "    ' interfere ': [' interf '],\n",
    "    ' introduce ': [' intoduce '],\n",
    "    ' lascivious ': [' lasc ', ' lasciv '],\n",
    "    ' lease ': [' leas '],\n",
    "    ' license ': [' lic ', ' licenc '],\n",
    "    ' license tag ': [' lictag '],\n",
    "    ' leave ': [' lve '],\n",
    "    ' manufacture ': [' man ', ' mfr '],\n",
    "    ' motor ': [' mot '],\n",
    "    ' occupied ': [' occup ', ' occp '], # not to confuse with unoccupied -- need space\n",
    "    ' offense ': [' offens ', ' offn '],\n",
    "    ' operate ': [' oper ', ' opert '],\n",
    "    ' permanent ': [' perm '],\n",
    "    ' person ': [' pers ', ' persn ', ' persnl '],\n",
    "    ' possession ': [' pos ', ' poss ', ' possess,'],\n",
    "    ' private ': [' priv '],\n",
    "    ' promise ': [' promis '],\n",
    "    ' property ': [' prop '],\n",
    "    ' public ': [' pub '],\n",
    "    ' purchase ': [' pur '],\n",
    "    ' railroad ': [' rail '],\n",
    "    ' redilver ': [' redeliv '],\n",
    "    ' revoke ': [' revk '],\n",
    "    ' scene ': [' scen '],\n",
    "    ' school ': [' ftsch ', ' scho ', ' scho '],\n",
    "    ' sell ': [' sel '],\n",
    "    ' sex ': [' sexual '], # for homogeneity\n",
    "    ' solicit ': [' solic ', ' solict '],\n",
    "    ' specialist ': [' speci '],\n",
    "    ' strangulation ': [' strang '],\n",
    "    ' structure ': [' struc ', ' struct '],\n",
    "    ' substance ': [' sub ', ' subst ', ' substa '],\n",
    "    ' sudden ': [' sudd '],\n",
    "    ' suspended ': [' susp ', ' suspd '],\n",
    "    ' traffick ': [' traf ', ' traff ', ' traffic '],\n",
    "    ' transmit ': [' trans '],\n",
    "    ' trespass ': [' tresspass '],\n",
    "    ' trirail ': [' tri rail '], # make 1-wd (tri-rail specific to FLA)\n",
    "    ' toward ': [' twrd '],\n",
    "    ' unauthorized ': [' unauth '],\n",
    "    ' uncovered ': [' uncov '],\n",
    "    ' unlawful ': [' unl ', ' unlaw '],\n",
    "    ' unoccupied ': [' unocc ', ' unoccup '],\n",
    "    ' vehicle ': [' veh '],\n",
    "    ' victim ': [' vict ', ' victm '],\n",
    "    ' vehicle identification number ': [' vin '],\n",
    "    ' violence ': [' viol ', ' vi '],\n",
    "    ' weapon ': [' weap ', ' wep '],\n",
    "}\n",
    "\n",
    "abbrev_map = {\n",
    "    'law enforcement officer ': ['leo '],\n",
    "    'driving under influence ': ['dui '],\n",
    "    'driving while intoxicated ': ['dwi '],\n",
    "    'driving while license suspended ': ['dwls '],\n",
    "    'firearm ': ['f arm '],\n",
    "    'vehicle identification number ': ['vin ']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary with replacement (str) --> mispellings (list of str) mapping\n",
    "r_replacement_map = {\n",
    "    ' accident ': [' acc ', ' accd '],\n",
    "    ' aggravated ': [' agg ', ' aggr '],\n",
    "    ' alcohol ': [' alch '], # NEW\n",
    "    ' alter ': [' alt '],\n",
    "    ' ammunition ': [' amm '],\n",
    "    ' amphetamine ': [' amp '],\n",
    "    ' attempt ': [' att ', ' attmp '],\n",
    "    ' attend ': [' attnd '],\n",
    "    ' battery ': [' batt ', ' bat '],\n",
    "    ' beverage ': [' bev '],\n",
    "    ' bodily ': [' bod '],\n",
    "    ' burglary ': ['burg ', ' burgl '],\n",
    "    ' business ': [' busn ', ' bus '], # ADDED bus\n",
    "    ' cancel ': [' can '],\n",
    "    ' church ': [' chur '], # NEW\n",
    "    ' counterfeit ': [' cntrft ', ' conterfeit ', ' contrft ', ' countrfeit'],\n",
    "    ' commit ': [' com '],\n",
    "    ' communication ': [' communic '],\n",
    "    ' compensation ': [' compensatn '],\n",
    "    ' conspiracy ': [' consp '],\n",
    "    ' control ': [' cont ', ' contr '],\n",
    "    ' conveyance ': [' conv ', ' conve '],\n",
    "    ' control ': [' cont ', ' contr '],\n",
    "    ' convict ': [' convic '],\n",
    "    ' credit ': [' cred '],\n",
    "    ' criminal ': [' crim ', ' crimin '], # ADDED crimin\n",
    "    ' cruelty ': [' crlty '],\n",
    "    ' custody ': [' cust '],\n",
    "    ' damage ': [' damg '],\n",
    "    ' dangerous ': [' dang '],\n",
    "    ' defendant ': [' deft '], # NEW\n",
    "    ' degree ': [' deg '],\n",
    "    ' delinquency ': [' delinq '],\n",
    "    ' delivery ': [' deliv ', ' del ', ' deliver '], # ADDED deliver\n",
    "    ' depend ': [' depnd '], # NEW\n",
    "    ' device ': [' dev '],\n",
    "    ' display ': [' disply '],\n",
    "    ' disqualified ': [' disqul '],\n",
    "    ' disorderly conduct ': [' doc '],\n",
    "    ' dollars ': [' dols '],\n",
    "    ' d u i ': [' dui '],\n",
    "    ' domestic ': [' dom ', ' dome '],\n",
    "    ' drive ': [' driv ', ' drivg ', ' drv '], # ADDED drv\n",
    "    ' dwelling ': [' dwell ', ' dwel '], # ADDED dwel\n",
    "    ' electronic ': [' elec '], # NEW\n",
    "    ' elderly ': [' elderlly '],\n",
    "    ' employee ': [' emplyee '],\n",
    "    ' enforcement ': [' enfor ', ' enforc '],\n",
    "    ' engage ': [' eng '], # NEW\n",
    "    ' establishment ': [' estab ', ' establishm '], # NEW\n",
    "    ' exhibition ': [' exhib '],\n",
    "    ' extinguisher ': [' extinquisher '],\n",
    "    ' facilitate ': [' fac '],\n",
    "    ' failure ': [' fail '],\n",
    "    ' family ': [' faml '],\n",
    "    ' felony ': [' fel '],\n",
    "    ' felon ': [' felo '],\n",
    "    ' firearm ': [' f arm '],\n",
    "    ' fraud ': [' frd ', ' fraudul', ' fraud ent '], # ADDED fraud ent\n",
    "    ' gambling ': [' gamb '],\n",
    "    ' gram ': [' g '], # check\n",
    "    ' great ': [' grt '],\n",
    "    ' hours ': [' hrs '], # NEW\n",
    "    ' informant ': ['informnt '],\n",
    "    ' injunction ': [' inj ', ' injunc ', ' injunct ', ' injunctn '],\n",
    "    ' instrument ': [' inst '],\n",
    "    ' insurance ': [' insur '], # NEW\n",
    "    ' intent ': [' int '],\n",
    "    ' interfere ': [' interf ', ' intrf '], # ADDED intrf\n",
    "    ' introduce ': [' intoduce '],\n",
    "    ' lascivious ': [' lasc ', ' lasciv '],\n",
    "    ' lease ': [' leas '],\n",
    "    ' license ': [' lic ', ' licenc '],\n",
    "    ' license tag ': [' lictag '],\n",
    "    ' leave ': [' lve '],\n",
    "    ' malicious ': [' malic '], # NEW\n",
    "    ' manufacture ': [' man ', ' mfr ', ' mfg '], # ADDED mfg\n",
    "    ' methadone ': [' methado '], # NEW\n",
    "    ' minor ': [' min '], # NEW\n",
    "    ' motor ': [' mot '],\n",
    "    ' obtain ': [' obt '], # NEW\n",
    "    ' occupied ': [' occup ', ' occp '],\n",
    "    ' offense ': [' offens ', ' offn '],\n",
    "    ' operate ': [' oper ', ' opert '],\n",
    "    ' paraphernalia ': [' para '], # NEW\n",
    "    ' pedestrian ': [' ped '], # NEW\n",
    "    ' permanent ': [' perm '],\n",
    "    ' person ': [' pers ', ' persn ', ' persnl ', ' prson '], # ADDED prson\n",
    "    ' possession ': [' pos ', ' poss ', ' possess ', ' posses '],\n",
    "    ' private ': [' priv '],\n",
    "    ' promise ': [' promis '],\n",
    "    ' property ': [' prop '],\n",
    "    ' prostitute ': [' prostitut '], # NEW\n",
    "    ' prostitution violation ': [' prostitutionviolation '], # NEW\n",
    "    ' protect ': [' prot '], # NEW\n",
    "    ' public ': [' pub '],\n",
    "    ' purchase ': [' pur '],\n",
    "    ' railroad ': [' rail '],\n",
    "    ' receipt ': [' rcpt '],\n",
    "    ' redilver ': [' redeliv '],\n",
    "    ' registration ': [' reg '], # NEW\n",
    "    ' responsibility ': [' resp '], # NEW\n",
    "    ' revoke ': [' revk '],\n",
    "    ' scene ': [' scen '],\n",
    "    ' school ': [' ftsch ', ' scho ', ' scho ', ' sch '], # ADDED sch\n",
    "    ' sell ': [' sel '],\n",
    "    ' sex ': [' sexual '], # for homogeneity\n",
    "    ' shop ': [' shp '], # NEW\n",
    "    ' solicit ': [' solic ', ' solict ', ' sol '], # ADDED sol\n",
    "    ' specialist ': [' speci '],\n",
    "    ' strangulation ': [' strang '],\n",
    "    ' structure ': [' struc ', ' struct '],\n",
    "    ' substance ': [' sub ', ' subst ', ' substa '],\n",
    "    ' sudden ': [' sudd '],\n",
    "    ' suspended ': [' susp ', ' suspd '],\n",
    "    ' traffick ': [' traf ', ' traff ', ' traffic '],\n",
    "    ' obstruct traffic ': [' obstruct traffick '], # NEW (acct for traffic/traffick diff)\n",
    "    ' transmit ': [' trans '],\n",
    "    ' trespass ': [' tresspass '],\n",
    "    ' trirail ': [' tri rail '], # make 1-wd (tri-rail specific to FLA)\n",
    "    ' toward ': [' twrd '],\n",
    "    ' unauthorized ': [' unauth ', ' unauthorizd '], # ADDED unauthorizd\n",
    "    ' uncovered ': [' uncov '],\n",
    "    ' under ': [' und '], # NEW\n",
    "    ' unlawful ': [' unl ', ' unlaw '],\n",
    "    ' unoccupied ': [' unocc ', ' unoccup '],\n",
    "    ' vehicle ': [' veh '],\n",
    "    ' verification ': [' verif '], # NEW\n",
    "    ' victim ': [' vict ', ' victm '],\n",
    "    ' vehicle identification number ': [' vin '],\n",
    "    ' violence ': [' viol ', ' vi '],\n",
    "    ' weapon ': [' weap ', ' wep '],\n",
    "    ' witness ': [' wit '], # NEW\n",
    "    ' years ': [' yrs '] # NEW\n",
    "}\n",
    "\n",
    "abbrev_map = {\n",
    "    'law enforcement officer ': ['leo '],\n",
    "    'driving under influence ': ['dui '],\n",
    "    'driving while intoxicated ': ['dwi '],\n",
    "    'driving while license suspended ': ['dwls '],\n",
    "    'firearm ': ['f arm '],\n",
    "    'vehicle identification number ': ['vin ']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Pre-processing Functions\n",
    "1. **get_chars_to_rmv:** Get list of non-alpha characters and replace with space\n",
    "2. **check_desc:** Get charge description containing a certain token (for reference).\n",
    "3. **clean_descs:** Remove chars_to_rmv; replace mispellings and remove any excess whitespace.\n",
    "4. **tokenize_descs:** Tokenize descriptions.\n",
    "5. **stem_tokens:** Stem each token in each description (exclude English stop words and tokens < 3 chars in length)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a list of non-alpha chars to remove, which can be fed into a replacement function as a regex\n",
    "def get_chars_to_rmv(charge_descs):\n",
    "    chars=[]\n",
    "    for d in charge_descs:\n",
    "        for t in d:\n",
    "            for c in t:\n",
    "                if not c.isalpha() and c not in chars:\n",
    "                    chars.append(c)\n",
    "    chars_to_rmv = ''.join(sorted(chars)).strip()\n",
    "    chars_to_rmv = '[' + chars_to_rmv + ']'\n",
    "    return chars_to_rmv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE WHEN DONE -- simply for checking full description of confusing tokens for context\n",
    "def check_desc(keyword):\n",
    "    for d in charge_descs:\n",
    "        if keyword in d.lower():\n",
    "            print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_descs(chars_to_rmv, charge_descs, replacement_map):\n",
    "    # remove non-alpha characters\n",
    "    charge_descs_clean = [re.sub(chars_to_rmv, ' ', desc.lower()) for desc in charge_descs]\n",
    "    # replace mispellings using replacement_map\n",
    "    for repl, mispellings in replacement_map.items():\n",
    "        for misp in mispellings:\n",
    "            charge_descs_clean = [re.sub(misp, repl, desc) for desc in charge_descs_clean]\n",
    "\n",
    "    # remove extra spaces\n",
    "    charge_descs_clean = [re.sub(' +', ' ', desc) for desc in charge_descs_clean]\n",
    "    return charge_descs_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_descs(charge_descs_clean):\n",
    "    # use nltk tokenizer to tokenize each description\n",
    "    tokenized_descs = [word_tokenize(desc.lower()) for desc in charge_descs_clean]\n",
    "    # sample of tokenized descriptions\n",
    "    return tokenized_descs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_tokens(tokenized_descs):\n",
    "    # make stemmer\n",
    "    stemmer = SnowballStemmer(language='english')\n",
    "\n",
    "    # get english stop words\n",
    "    swds = stopwords.words('english')\n",
    "\n",
    "    # list for toring tokenized & stemmed descriptions\n",
    "    tokenized_stemmed = []\n",
    "    # list for storing stemmed/token/description triplets\n",
    "    stem_token_descs = []\n",
    "\n",
    "    # stem each token in each description\n",
    "    for desc in tokenized_descs:\n",
    "        stemmed = [(stemmer.stem(token)) for token in desc if (len(token) > 2 and token not in swds)]\n",
    "        tokenized_stemmed.append(stemmed)\n",
    "        # also build a list containing stemmed token, original token, and the description it came from \n",
    "        # (for reference and debugging purposes)\n",
    "        triplet = [(stemmer.stem(token), token, ' '.join(desc)) for token in desc if len(token) > 2]\n",
    "        stem_token_descs.append(triplet)\n",
    "    return tokenized_stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preprocess First Charge Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[#$()+,-./0123456789<>]'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars_to_rmv = get_chars_to_rmv(charge_descs)\n",
    "chars_to_rmv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' aggravated assault w firearm ',\n",
       " ' felony battery w prior convict ',\n",
       " ' possession of cocaine ',\n",
       " ' possession of cannabis ',\n",
       " ' arrest case no charge ',\n",
       " ' battery ',\n",
       " ' possession burglary tools ',\n",
       " ' arrest case no charge ',\n",
       " ' battery ',\n",
       " ' insurance fraud ']"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean descriptions\n",
    "charge_descs_clean = clean_descs(chars_to_rmv, charge_descs, r_replacement_map)\n",
    "# sample of cleaned charge descriptions\n",
    "charge_descs_clean[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['aggravated', 'assault', 'w', 'firearm'],\n",
       " ['felony', 'battery', 'w', 'prior', 'convict'],\n",
       " ['possession', 'of', 'cocaine'],\n",
       " ['possession', 'of', 'cannabis'],\n",
       " ['arrest', 'case', 'no', 'charge'],\n",
       " ['battery'],\n",
       " ['possession', 'burglary', 'tools'],\n",
       " ['arrest', 'case', 'no', 'charge'],\n",
       " ['battery'],\n",
       " ['insurance', 'fraud']]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize\n",
    "tokenized_descs = tokenize_descs(charge_descs_clean)\n",
    "# sample of tokenized descriptions\n",
    "tokenized_descs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aggrav, assault, firearm',\n",
      " 'feloni, batteri, prior, convict',\n",
      " 'possess, cocain',\n",
      " 'possess, cannabi',\n",
      " 'arrest, case, charg',\n",
      " 'batteri',\n",
      " 'possess, burglari, tool',\n",
      " 'arrest, case, charg',\n",
      " 'batteri',\n",
      " 'insur, fraud']\n",
      "\n",
      "number of unique tokens (vocab length): 421\n",
      "number of unique charge descriptions: 406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['abet',\n",
       " 'abus',\n",
       " 'accessori',\n",
       " 'accid',\n",
       " 'act',\n",
       " 'actual',\n",
       " 'adult',\n",
       " 'aggrav',\n",
       " 'aggress',\n",
       " 'agre']"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stem and remove stopwords\n",
    "tokenized_stemmed = stem_tokens(tokenized_descs)\n",
    "tokenized_stemmed = [', '.join(desc) for desc in tokenized_stemmed]\n",
    "# sample of stemmed, tokenized descriptions\n",
    "pprint(tokenized_stemmed[:10])\n",
    "\n",
    "# make sorted list of unique tokens (vocabulary)\n",
    "flat_unq_tokens = sorted(set([token for desc in tokenized_stemmed for token in desc.split(', ')]))\n",
    "print('\\nnumber of unique tokens (vocab length):', len(flat_unq_tokens))\n",
    "print('number of unique charge descriptions:', len(set([' '.join(desc) for desc in tokenized_stemmed])))\n",
    "\n",
    "# sample of stemmed, tokenized descriptions\n",
    "flat_unq_tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'id': compas_df_charge_filt['id'], 'name': compas_df_charge_filt['name'], 'charge description': compas_df_charge_filt['c_charge_desc'], \n",
    "     'tokenized_stemmed description': tokenized_stemmed}\n",
    "charge_mappings = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>charge description</th>\n",
       "      <th>tokenized_stemmed description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>miguel hernandez</td>\n",
       "      <td>Aggravated Assault w/Firearm</td>\n",
       "      <td>aggrav, assault, firearm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>Felony Battery w/Prior Convict</td>\n",
       "      <td>feloni, batteri, prior, convict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ed philo</td>\n",
       "      <td>Possession of Cocaine</td>\n",
       "      <td>possess, cocain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>marcu brown</td>\n",
       "      <td>Possession of Cannabis</td>\n",
       "      <td>possess, cannabi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>bouthy pierrelouis</td>\n",
       "      <td>arrest case no charge</td>\n",
       "      <td>arrest, case, charg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                name              charge description  \\\n",
       "0   1    miguel hernandez    Aggravated Assault w/Firearm   \n",
       "1   3         kevon dixon  Felony Battery w/Prior Convict   \n",
       "2   4            ed philo           Possession of Cocaine   \n",
       "3   5         marcu brown          Possession of Cannabis   \n",
       "4   6  bouthy pierrelouis           arrest case no charge   \n",
       "\n",
       "     tokenized_stemmed description  \n",
       "0         aggrav, assault, firearm  \n",
       "1  feloni, batteri, prior, convict  \n",
       "2                  possess, cocain  \n",
       "3                 possess, cannabi  \n",
       "4              arrest, case, charg  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charge_mappings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Second Charge Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' Felony Battery (Dom Strang) ',\n",
       " ' Driving Under The Influence ',\n",
       " ' Poss of Firearm by Convic Felo ',\n",
       " ' Battery ',\n",
       " ' Driving License Suspended ',\n",
       " ' Grand Theft (Motor Vehicle) ',\n",
       " ' Criminal Mischief>$200<$1000 ',\n",
       " ' Grand Theft in the 3rd Degree ',\n",
       " ' Possession of Cocaine ',\n",
       " ' Poss Cocaine/Intent To Del/Sel ']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get non-NaN r_charge descriptions as a list\n",
    "r_compas_df_charge_filt = compas_df[compas_df['r_charge_desc'].isna() == False]\n",
    "r_charge_descs = list(r_compas_df_charge_filt['r_charge_desc'])\n",
    "r_charge_descs = [' ' + desc + ' ' for desc in r_charge_descs]\n",
    "print(len(r_charge_descs))\n",
    "r_charge_descs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"$()+,-./0123456789<>]'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get chars to remove from r crimes\n",
    "r_chars_to_rmv = get_chars_to_rmv(r_charge_descs)\n",
    "r_chars_to_rmv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' felony battery domestic strangulation ',\n",
       " ' driving under the influence ',\n",
       " ' possession of firearm by convict felon ',\n",
       " ' battery ',\n",
       " ' driving license suspended ',\n",
       " ' grand theft motor vehicle ',\n",
       " ' criminal mischief ',\n",
       " ' grand theft in the rd degree ',\n",
       " ' possession of cocaine ',\n",
       " ' possession cocaine intent to delivery sell ',\n",
       " ' prowling loitering ',\n",
       " ' operating w o valid license ',\n",
       " ' possession cannabis grams or less ',\n",
       " ' driving license suspended ',\n",
       " ' possession cannabis grams or less ',\n",
       " ' false imprisonment ',\n",
       " ' grand theft motor vehicle ',\n",
       " ' resist obstruct w o violence ',\n",
       " ' possession cannabis grams or less ',\n",
       " ' grand theft in the rd degree ']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample of cleaned charge descriptions\n",
    "r_charge_descs_clean = clean_descs(r_chars_to_rmv, r_charge_descs, r_replacement_map)\n",
    "# sample of cleaned charge descriptions\n",
    "r_charge_descs_clean[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['felony', 'battery', 'domestic', 'strangulation'],\n",
       " ['driving', 'under', 'the', 'influence'],\n",
       " ['possession', 'of', 'firearm', 'by', 'convict', 'felon'],\n",
       " ['battery'],\n",
       " ['driving', 'license', 'suspended'],\n",
       " ['grand', 'theft', 'motor', 'vehicle'],\n",
       " ['criminal', 'mischief'],\n",
       " ['grand', 'theft', 'in', 'the', 'rd', 'degree'],\n",
       " ['possession', 'of', 'cocaine'],\n",
       " ['possession', 'cocaine', 'intent', 'to', 'delivery', 'sell']]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize each description\n",
    "r_tokenized_descs = tokenize_descs(r_charge_descs_clean)\n",
    "# sample of tokenized descriptions\n",
    "r_tokenized_descs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feloni, batteri, domest, strangul', 'drive, influenc', 'possess, firearm, convict, felon', 'batteri', 'drive, licens, suspend', 'grand, theft, motor, vehicl', 'crimin, mischief', 'grand, theft, degre', 'possess, cocain', 'possess, cocain, intent, deliveri, sell']\n"
     ]
    }
   ],
   "source": [
    "# stem each token in each description & remove stop words\n",
    "r_tokenized_stemmed = stem_tokens(r_tokenized_descs)\n",
    "r_tokenized_stemmed = [', '.join(desc) for desc in r_tokenized_stemmed]\n",
    "# sample of stemmed, tokenized descriptions\n",
    "print(r_tokenized_stemmed[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>charge description</th>\n",
       "      <th>r_tokenized_stemmed description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>Felony Battery (Dom Strang)</td>\n",
       "      <td>feloni, batteri, domest, strangul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ed philo</td>\n",
       "      <td>Driving Under The Influence</td>\n",
       "      <td>drive, influenc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>edward riddle</td>\n",
       "      <td>Poss of Firearm by Convic Felo</td>\n",
       "      <td>possess, firearm, convict, felon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13</td>\n",
       "      <td>bo bradac</td>\n",
       "      <td>Battery</td>\n",
       "      <td>batteri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15</td>\n",
       "      <td>ellyaher lanza</td>\n",
       "      <td>Driving License Suspended</td>\n",
       "      <td>drive, licens, suspend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7201</th>\n",
       "      <td>10985</td>\n",
       "      <td>kyle miller</td>\n",
       "      <td>Operating W/O Valid License</td>\n",
       "      <td>oper, valid, licens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7205</th>\n",
       "      <td>10990</td>\n",
       "      <td>christopher tun</td>\n",
       "      <td>Assault</td>\n",
       "      <td>assault</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7206</th>\n",
       "      <td>10992</td>\n",
       "      <td>alexander vega</td>\n",
       "      <td>Possess Cannabis/20 Grams Or Less</td>\n",
       "      <td>possess, cannabi, gram, less</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7207</th>\n",
       "      <td>10994</td>\n",
       "      <td>jarred payne</td>\n",
       "      <td>Possession of Cannabis</td>\n",
       "      <td>possess, cannabi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7213</th>\n",
       "      <td>11001</td>\n",
       "      <td>florencia sanmartin</td>\n",
       "      <td>Operating W/O Valid License</td>\n",
       "      <td>oper, valid, licens</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3413 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                 name                 charge description  \\\n",
       "1         3          kevon dixon        Felony Battery (Dom Strang)   \n",
       "2         4             ed philo        Driving Under The Influence   \n",
       "6         8        edward riddle     Poss of Firearm by Convic Felo   \n",
       "9        13            bo bradac                            Battery   \n",
       "11       15       ellyaher lanza          Driving License Suspended   \n",
       "...     ...                  ...                                ...   \n",
       "7201  10985          kyle miller        Operating W/O Valid License   \n",
       "7205  10990      christopher tun                            Assault   \n",
       "7206  10992       alexander vega  Possess Cannabis/20 Grams Or Less   \n",
       "7207  10994         jarred payne             Possession of Cannabis   \n",
       "7213  11001  florencia sanmartin        Operating W/O Valid License   \n",
       "\n",
       "        r_tokenized_stemmed description  \n",
       "1     feloni, batteri, domest, strangul  \n",
       "2                       drive, influenc  \n",
       "6      possess, firearm, convict, felon  \n",
       "9                               batteri  \n",
       "11               drive, licens, suspend  \n",
       "...                                 ...  \n",
       "7201                oper, valid, licens  \n",
       "7205                            assault  \n",
       "7206       possess, cannabi, gram, less  \n",
       "7207                   possess, cannabi  \n",
       "7213                oper, valid, licens  \n",
       "\n",
       "[3413 rows x 4 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'id': r_compas_df_charge_filt['id'], 'name': r_compas_df_charge_filt['name'], \n",
    "     'charge description': r_compas_df_charge_filt['r_charge_desc'], \n",
    "     'r_tokenized_stemmed description': r_tokenized_stemmed}\n",
    "r_charge_mappings = pd.DataFrame(data=d)\n",
    "r_charge_mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for Common Token Analysis / Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# rows total: 7214\n",
      "# rows where c_charge is non-NaN: 7185\n",
      "# rows where r_charge is non-NaN: 3413\n",
      "# rows where c_charge and r_charge both non-NaN: 3393\n"
     ]
    }
   ],
   "source": [
    "# check lengths of df slices before merge\n",
    "print('# rows total:', len(compas_df))\n",
    "print('# rows where c_charge is non-NaN:', len(charge_mappings))\n",
    "print('# rows where r_charge is non-NaN:', len(r_charge_mappings))\n",
    "# get df rows where c_charge and r_charge both non-NaN\n",
    "cr_idx = (compas_df['c_charge_desc'].isna() == False) & (compas_df['r_charge_desc'].isna() == False)\n",
    "print('# rows where c_charge and r_charge both non-NaN:', len(cr_idx[cr_idx == True]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df_merged = compas_df.merge(charge_mappings[['id', 'tokenized_stemmed description']], how='outer', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_df_merged = c_df_merged.merge(r_charge_mappings[['id', 'r_tokenized_stemmed description']], how='outer', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>race</th>\n",
       "      <th>c_charge_desc</th>\n",
       "      <th>tokenized_stemmed description</th>\n",
       "      <th>two_year_recid</th>\n",
       "      <th>r_charge_desc</th>\n",
       "      <th>r_tokenized_stemmed description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>miguel hernandez</td>\n",
       "      <td>Other</td>\n",
       "      <td>Aggravated Assault w/Firearm</td>\n",
       "      <td>aggrav, assault, firearm</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>African-American</td>\n",
       "      <td>Felony Battery w/Prior Convict</td>\n",
       "      <td>feloni, batteri, prior, convict</td>\n",
       "      <td>1</td>\n",
       "      <td>Felony Battery (Dom Strang)</td>\n",
       "      <td>feloni, batteri, domest, strangul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ed philo</td>\n",
       "      <td>African-American</td>\n",
       "      <td>Possession of Cocaine</td>\n",
       "      <td>possess, cocain</td>\n",
       "      <td>1</td>\n",
       "      <td>Driving Under The Influence</td>\n",
       "      <td>drive, influenc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>marcu brown</td>\n",
       "      <td>African-American</td>\n",
       "      <td>Possession of Cannabis</td>\n",
       "      <td>possess, cannabi</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>bouthy pierrelouis</td>\n",
       "      <td>Other</td>\n",
       "      <td>arrest case no charge</td>\n",
       "      <td>arrest, case, charg</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                name              race                   c_charge_desc  \\\n",
       "0   1    miguel hernandez             Other    Aggravated Assault w/Firearm   \n",
       "1   3         kevon dixon  African-American  Felony Battery w/Prior Convict   \n",
       "2   4            ed philo  African-American           Possession of Cocaine   \n",
       "3   5         marcu brown  African-American          Possession of Cannabis   \n",
       "4   6  bouthy pierrelouis             Other           arrest case no charge   \n",
       "\n",
       "     tokenized_stemmed description  two_year_recid  \\\n",
       "0         aggrav, assault, firearm               0   \n",
       "1  feloni, batteri, prior, convict               1   \n",
       "2                  possess, cocain               1   \n",
       "3                 possess, cannabi               0   \n",
       "4              arrest, case, charg               0   \n",
       "\n",
       "                 r_charge_desc    r_tokenized_stemmed description  \n",
       "0                          NaN                                NaN  \n",
       "1  Felony Battery (Dom Strang)  feloni, batteri, domest, strangul  \n",
       "2  Driving Under The Influence                    drive, influenc  \n",
       "3                          NaN                                NaN  \n",
       "4                          NaN                                NaN  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_filt = cr_df_merged[['id', 'name', 'race', 'c_charge_desc', 'tokenized_stemmed description', 'two_year_recid', 'r_charge_desc', 'r_tokenized_stemmed description']]\n",
    "merged_filt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_filt.to_csv('merged_filt_NEW.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
